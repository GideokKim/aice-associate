{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 02. 딥러닝으로 AI모델링하기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 딥러닝 프레임워크"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 텐서플로 설치 및 활용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\nexr\\anaconda3\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.5)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (23.1.21)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (15.0.6.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.51.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.2)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.16.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\nexr\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "# tensorflow 라이브러리 설치하기\n",
    "# !pip install tensorflow\n",
    "# 이 프로젝트는 uv로 관리하므로 아래 명령어로 설치함\n",
    "# uv add tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 10:23:32.593711: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750901012.649501   14719 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750901012.668485   14719 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750901012.814231   14719 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750901012.814258   14719 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750901012.814259   14719 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750901012.814260   14719 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-26 10:23:32.829043: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n"
     ]
    }
   ],
   "source": [
    "# 설치된 텐서플로 버전 확인하기\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T04:22:03.907175Z",
     "start_time": "2023-03-10T04:22:03.894965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 데이터 : [[ 1]\n",
      " [ 2]\n",
      " [ 3]\n",
      " [ 4]\n",
      " [ 5]\n",
      " [ 6]\n",
      " [ 7]\n",
      " [ 8]\n",
      " [ 9]\n",
      " [10]]\n",
      "입력 데이터 형태: (10, 1)\n",
      "출력 데이터: [ 3  5  7  9 11 13 15 17 19 21]\n",
      "출력 데이터 형태 : (10,)\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# 모델 학습 데이터 생성하기\n",
    "x = [1, 2, 3, 4,  5, 6,  7,  8,  9, 10]\n",
    "y = [3, 5, 7, 9, 11, 13, 15, 17, 19, 21]\n",
    "x_train = np.array(x)\n",
    "x_train = x_train.reshape(-1, 1)\n",
    "y_train = np.array(y)\n",
    "\n",
    "print(f'입력 데이터 : {x_train}')\n",
    "print(f'입력 데이터 형태: {x_train.shape}')\n",
    "print(f'출력 데이터: {y_train}')\n",
    "print(f'출력 데이터 형태 : {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noah/workspace/certificates/aice-associate/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "W0000 00:00:1750901317.840860   14719 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m2\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (8.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2\u001b[0m (8.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (8.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2\u001b[0m (8.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Keras의 Sequential 모델 구성하기\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=42) #모델 시드 고정하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=1, input_shape=(1,),kernel_initializer=initializer))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 학습시킬 최적화 방법, loss 계산 방법, 평가 방법 설정하기\n",
    "model.compile(optimizer='sgd', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 323.2250 - mae: 16.1452\n",
      "Epoch 2/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 14.9011 - mae: 3.5555\n",
      "Epoch 3/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.7542 - mae: 0.8584\n",
      "Epoch 4/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1045 - mae: 0.2802\n",
      "Epoch 5/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0741 - mae: 0.2255\n",
      "Epoch 6/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0721 - mae: 0.2238\n",
      "Epoch 7/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0715 - mae: 0.2230\n",
      "Epoch 8/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0709 - mae: 0.2223\n",
      "Epoch 9/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0703 - mae: 0.2214\n",
      "Epoch 10/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0697 - mae: 0.2205\n",
      "Epoch 11/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0691 - mae: 0.2196\n",
      "Epoch 12/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0685 - mae: 0.2187\n",
      "Epoch 13/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0679 - mae: 0.2178\n",
      "Epoch 14/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0674 - mae: 0.2168\n",
      "Epoch 15/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0668 - mae: 0.2159\n",
      "Epoch 16/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0663 - mae: 0.2150\n",
      "Epoch 17/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0657 - mae: 0.2141\n",
      "Epoch 18/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0651 - mae: 0.2132\n",
      "Epoch 19/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0646 - mae: 0.2123\n",
      "Epoch 20/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0641 - mae: 0.2114\n",
      "Epoch 21/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0635 - mae: 0.2106\n",
      "Epoch 22/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0630 - mae: 0.2097\n",
      "Epoch 23/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0625 - mae: 0.2088\n",
      "Epoch 24/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0619 - mae: 0.2079\n",
      "Epoch 25/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0614 - mae: 0.2070\n",
      "Epoch 26/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0609 - mae: 0.2062\n",
      "Epoch 27/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0604 - mae: 0.2053\n",
      "Epoch 28/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0599 - mae: 0.2044\n",
      "Epoch 29/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0594 - mae: 0.2036\n",
      "Epoch 30/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0589 - mae: 0.2027\n",
      "Epoch 31/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0584 - mae: 0.2019\n",
      "Epoch 32/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0579 - mae: 0.2010\n",
      "Epoch 33/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0574 - mae: 0.2002\n",
      "Epoch 34/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0569 - mae: 0.1993\n",
      "Epoch 35/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0565 - mae: 0.1985\n",
      "Epoch 36/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0560 - mae: 0.1977\n",
      "Epoch 37/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0555 - mae: 0.1968\n",
      "Epoch 38/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0551 - mae: 0.1960\n",
      "Epoch 39/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0546 - mae: 0.1952\n",
      "Epoch 40/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0541 - mae: 0.1944\n",
      "Epoch 41/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0537 - mae: 0.1936\n",
      "Epoch 42/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0532 - mae: 0.1927\n",
      "Epoch 43/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0528 - mae: 0.1919\n",
      "Epoch 44/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0523 - mae: 0.1911\n",
      "Epoch 45/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0519 - mae: 0.1903\n",
      "Epoch 46/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0515 - mae: 0.1895\n",
      "Epoch 47/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0510 - mae: 0.1887\n",
      "Epoch 48/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0506 - mae: 0.1879\n",
      "Epoch 49/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0502 - mae: 0.1871\n",
      "Epoch 50/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0498 - mae: 0.1864\n",
      "Epoch 51/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0493 - mae: 0.1856\n",
      "Epoch 52/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0489 - mae: 0.1848\n",
      "Epoch 53/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0485 - mae: 0.1840\n",
      "Epoch 54/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0481 - mae: 0.1832\n",
      "Epoch 55/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0477 - mae: 0.1825\n",
      "Epoch 56/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0473 - mae: 0.1817\n",
      "Epoch 57/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0469 - mae: 0.1810\n",
      "Epoch 58/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0465 - mae: 0.1802\n",
      "Epoch 59/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0461 - mae: 0.1794\n",
      "Epoch 60/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0457 - mae: 0.1787\n",
      "Epoch 61/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0454 - mae: 0.1779\n",
      "Epoch 62/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0450 - mae: 0.1772\n",
      "Epoch 63/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0446 - mae: 0.1764\n",
      "Epoch 64/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0442 - mae: 0.1757\n",
      "Epoch 65/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0439 - mae: 0.1750\n",
      "Epoch 66/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0435 - mae: 0.1742\n",
      "Epoch 67/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0431 - mae: 0.1735\n",
      "Epoch 68/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0428 - mae: 0.1728\n",
      "Epoch 69/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0424 - mae: 0.1720\n",
      "Epoch 70/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0421 - mae: 0.1713\n",
      "Epoch 71/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0417 - mae: 0.1706\n",
      "Epoch 72/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0414 - mae: 0.1699\n",
      "Epoch 73/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0410 - mae: 0.1692\n",
      "Epoch 74/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0407 - mae: 0.1685\n",
      "Epoch 75/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0403 - mae: 0.1677\n",
      "Epoch 76/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0400 - mae: 0.1670\n",
      "Epoch 77/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0396 - mae: 0.1663\n",
      "Epoch 78/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0393 - mae: 0.1656\n",
      "Epoch 79/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0390 - mae: 0.1649\n",
      "Epoch 80/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0387 - mae: 0.1643\n",
      "Epoch 81/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0383 - mae: 0.1636\n",
      "Epoch 82/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0380 - mae: 0.1629\n",
      "Epoch 83/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0377 - mae: 0.1622\n",
      "Epoch 84/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0374 - mae: 0.1615\n",
      "Epoch 85/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0371 - mae: 0.1608\n",
      "Epoch 86/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0368 - mae: 0.1602\n",
      "Epoch 87/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0364 - mae: 0.1595\n",
      "Epoch 88/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0361 - mae: 0.1588\n",
      "Epoch 89/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0358 - mae: 0.1582\n",
      "Epoch 90/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0355 - mae: 0.1575\n",
      "Epoch 91/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0352 - mae: 0.1568\n",
      "Epoch 92/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0349 - mae: 0.1562\n",
      "Epoch 93/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0347 - mae: 0.1555\n",
      "Epoch 94/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0344 - mae: 0.1549\n",
      "Epoch 95/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0341 - mae: 0.1542\n",
      "Epoch 96/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0338 - mae: 0.1536\n",
      "Epoch 97/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0335 - mae: 0.1529\n",
      "Epoch 98/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0332 - mae: 0.1523\n",
      "Epoch 99/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0329 - mae: 0.1516\n",
      "Epoch 100/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0327 - mae: 0.1510\n",
      "Epoch 101/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0324 - mae: 0.1504\n",
      "Epoch 102/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0321 - mae: 0.1497\n",
      "Epoch 103/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0319 - mae: 0.1491\n",
      "Epoch 104/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0316 - mae: 0.1485\n",
      "Epoch 105/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0313 - mae: 0.1479\n",
      "Epoch 106/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0311 - mae: 0.1472\n",
      "Epoch 107/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0308 - mae: 0.1466\n",
      "Epoch 108/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0305 - mae: 0.1460\n",
      "Epoch 109/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0303 - mae: 0.1454\n",
      "Epoch 110/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0300 - mae: 0.1448\n",
      "Epoch 111/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0298 - mae: 0.1442\n",
      "Epoch 112/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0295 - mae: 0.1436\n",
      "Epoch 113/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0293 - mae: 0.1430\n",
      "Epoch 114/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0290 - mae: 0.1424\n",
      "Epoch 115/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0288 - mae: 0.1418\n",
      "Epoch 116/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0286 - mae: 0.1412\n",
      "Epoch 117/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0283 - mae: 0.1406\n",
      "Epoch 118/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0281 - mae: 0.1400\n",
      "Epoch 119/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0278 - mae: 0.1394\n",
      "Epoch 120/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0276 - mae: 0.1388\n",
      "Epoch 121/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0274 - mae: 0.1382\n",
      "Epoch 122/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0271 - mae: 0.1376\n",
      "Epoch 123/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0269 - mae: 0.1371\n",
      "Epoch 124/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0267 - mae: 0.1365\n",
      "Epoch 125/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0265 - mae: 0.1359\n",
      "Epoch 126/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0262 - mae: 0.1353\n",
      "Epoch 127/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0260 - mae: 0.1348\n",
      "Epoch 128/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0258 - mae: 0.1342\n",
      "Epoch 129/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0256 - mae: 0.1336\n",
      "Epoch 130/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0254 - mae: 0.1331\n",
      "Epoch 131/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0252 - mae: 0.1325\n",
      "Epoch 132/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0250 - mae: 0.1320\n",
      "Epoch 133/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0247 - mae: 0.1314\n",
      "Epoch 134/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0245 - mae: 0.1309\n",
      "Epoch 135/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0243 - mae: 0.1303\n",
      "Epoch 136/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0241 - mae: 0.1298\n",
      "Epoch 137/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0239 - mae: 0.1292\n",
      "Epoch 138/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0237 - mae: 0.1287\n",
      "Epoch 139/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0235 - mae: 0.1281\n",
      "Epoch 140/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0233 - mae: 0.1276\n",
      "Epoch 141/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0231 - mae: 0.1271\n",
      "Epoch 142/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0229 - mae: 0.1265\n",
      "Epoch 143/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0227 - mae: 0.1260\n",
      "Epoch 144/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0226 - mae: 0.1255\n",
      "Epoch 145/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0224 - mae: 0.1249\n",
      "Epoch 146/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0222 - mae: 0.1244\n",
      "Epoch 147/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0220 - mae: 0.1239\n",
      "Epoch 148/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0218 - mae: 0.1234\n",
      "Epoch 149/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0216 - mae: 0.1229\n",
      "Epoch 150/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0214 - mae: 0.1223\n",
      "Epoch 151/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0213 - mae: 0.1218\n",
      "Epoch 152/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0211 - mae: 0.1213\n",
      "Epoch 153/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0209 - mae: 0.1208\n",
      "Epoch 154/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0207 - mae: 0.1203\n",
      "Epoch 155/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0206 - mae: 0.1198\n",
      "Epoch 156/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0204 - mae: 0.1193\n",
      "Epoch 157/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0202 - mae: 0.1188\n",
      "Epoch 158/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0201 - mae: 0.1183\n",
      "Epoch 159/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0199 - mae: 0.1178\n",
      "Epoch 160/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0197 - mae: 0.1173\n",
      "Epoch 161/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0196 - mae: 0.1168\n",
      "Epoch 162/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0194 - mae: 0.1163\n",
      "Epoch 163/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0192 - mae: 0.1158\n",
      "Epoch 164/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0191 - mae: 0.1153\n",
      "Epoch 165/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0189 - mae: 0.1149\n",
      "Epoch 166/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0187 - mae: 0.1144\n",
      "Epoch 167/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0186 - mae: 0.1139\n",
      "Epoch 168/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0184 - mae: 0.1134\n",
      "Epoch 169/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0183 - mae: 0.1129\n",
      "Epoch 170/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0181 - mae: 0.1125\n",
      "Epoch 171/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0180 - mae: 0.1120\n",
      "Epoch 172/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0178 - mae: 0.1115\n",
      "Epoch 173/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0177 - mae: 0.1111\n",
      "Epoch 174/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0175 - mae: 0.1106\n",
      "Epoch 175/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0174 - mae: 0.1101\n",
      "Epoch 176/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0172 - mae: 0.1097\n",
      "Epoch 177/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0171 - mae: 0.1092\n",
      "Epoch 178/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0169 - mae: 0.1087\n",
      "Epoch 179/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0168 - mae: 0.1083\n",
      "Epoch 180/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0167 - mae: 0.1078\n",
      "Epoch 181/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0165 - mae: 0.1074\n",
      "Epoch 182/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0164 - mae: 0.1069\n",
      "Epoch 183/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0162 - mae: 0.1065\n",
      "Epoch 184/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0161 - mae: 0.1060\n",
      "Epoch 185/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0160 - mae: 0.1056\n",
      "Epoch 186/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0158 - mae: 0.1051\n",
      "Epoch 187/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0157 - mae: 0.1047\n",
      "Epoch 188/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0156 - mae: 0.1043\n",
      "Epoch 189/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0154 - mae: 0.1038\n",
      "Epoch 190/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0153 - mae: 0.1034\n",
      "Epoch 191/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0152 - mae: 0.1030\n",
      "Epoch 192/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0151 - mae: 0.1025\n",
      "Epoch 193/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0149 - mae: 0.1021\n",
      "Epoch 194/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0148 - mae: 0.1017\n",
      "Epoch 195/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0147 - mae: 0.1012\n",
      "Epoch 196/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0146 - mae: 0.1008\n",
      "Epoch 197/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0144 - mae: 0.1004\n",
      "Epoch 198/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0143 - mae: 0.1000\n",
      "Epoch 199/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0142 - mae: 0.0995\n",
      "Epoch 200/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0141 - mae: 0.0991\n",
      "Epoch 201/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0140 - mae: 0.0987\n",
      "Epoch 202/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0138 - mae: 0.0983\n",
      "Epoch 203/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0137 - mae: 0.0979\n",
      "Epoch 204/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0136 - mae: 0.0975\n",
      "Epoch 205/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0135 - mae: 0.0971\n",
      "Epoch 206/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0134 - mae: 0.0967\n",
      "Epoch 207/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0133 - mae: 0.0963\n",
      "Epoch 208/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0132 - mae: 0.0958\n",
      "Epoch 209/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0131 - mae: 0.0954\n",
      "Epoch 210/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0129 - mae: 0.0950\n",
      "Epoch 211/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0128 - mae: 0.0946\n",
      "Epoch 212/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0127 - mae: 0.0942\n",
      "Epoch 213/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0126 - mae: 0.0939\n",
      "Epoch 214/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0125 - mae: 0.0935\n",
      "Epoch 215/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0124 - mae: 0.0931\n",
      "Epoch 216/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0123 - mae: 0.0927\n",
      "Epoch 217/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0122 - mae: 0.0923\n",
      "Epoch 218/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0121 - mae: 0.0919\n",
      "Epoch 219/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0120 - mae: 0.0915\n",
      "Epoch 220/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0119 - mae: 0.0911\n",
      "Epoch 221/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0118 - mae: 0.0907\n",
      "Epoch 222/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0117 - mae: 0.0904\n",
      "Epoch 223/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0116 - mae: 0.0900\n",
      "Epoch 224/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0115 - mae: 0.0896\n",
      "Epoch 225/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0114 - mae: 0.0892\n",
      "Epoch 226/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0113 - mae: 0.0889\n",
      "Epoch 227/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0112 - mae: 0.0885\n",
      "Epoch 228/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0111 - mae: 0.0881\n",
      "Epoch 229/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0110 - mae: 0.0877\n",
      "Epoch 230/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0109 - mae: 0.0874\n",
      "Epoch 231/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0108 - mae: 0.0870\n",
      "Epoch 232/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0108 - mae: 0.0866\n",
      "Epoch 233/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0107 - mae: 0.0863\n",
      "Epoch 234/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0106 - mae: 0.0859\n",
      "Epoch 235/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0105 - mae: 0.0856\n",
      "Epoch 236/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0104 - mae: 0.0852\n",
      "Epoch 237/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0103 - mae: 0.0848\n",
      "Epoch 238/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0102 - mae: 0.0845\n",
      "Epoch 239/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0101 - mae: 0.0841\n",
      "Epoch 240/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0101 - mae: 0.0838\n",
      "Epoch 241/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0100 - mae: 0.0834\n",
      "Epoch 242/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0099 - mae: 0.0831\n",
      "Epoch 243/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0098 - mae: 0.0827\n",
      "Epoch 244/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0097 - mae: 0.0824\n",
      "Epoch 245/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0096 - mae: 0.0820\n",
      "Epoch 246/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0096 - mae: 0.0817\n",
      "Epoch 247/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0095 - mae: 0.0813\n",
      "Epoch 248/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0094 - mae: 0.0810\n",
      "Epoch 249/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0093 - mae: 0.0807\n",
      "Epoch 250/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0092 - mae: 0.0803\n",
      "Epoch 251/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0092 - mae: 0.0800\n",
      "Epoch 252/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0091 - mae: 0.0796\n",
      "Epoch 253/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0090 - mae: 0.0793\n",
      "Epoch 254/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0089 - mae: 0.0790\n",
      "Epoch 255/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0089 - mae: 0.0786\n",
      "Epoch 256/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0088 - mae: 0.0783\n",
      "Epoch 257/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0087 - mae: 0.0780\n",
      "Epoch 258/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0086 - mae: 0.0777\n",
      "Epoch 259/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0086 - mae: 0.0773\n",
      "Epoch 260/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0085 - mae: 0.0770\n",
      "Epoch 261/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0084 - mae: 0.0767\n",
      "Epoch 262/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0084 - mae: 0.0764\n",
      "Epoch 263/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0083 - mae: 0.0760\n",
      "Epoch 264/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0082 - mae: 0.0757\n",
      "Epoch 265/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0081 - mae: 0.0754\n",
      "Epoch 266/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0081 - mae: 0.0751\n",
      "Epoch 267/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0080 - mae: 0.0748\n",
      "Epoch 268/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0079 - mae: 0.0745\n",
      "Epoch 269/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0079 - mae: 0.0741\n",
      "Epoch 270/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0078 - mae: 0.0738\n",
      "Epoch 271/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0077 - mae: 0.0735\n",
      "Epoch 272/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0077 - mae: 0.0732\n",
      "Epoch 273/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0076 - mae: 0.0729\n",
      "Epoch 274/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0076 - mae: 0.0726\n",
      "Epoch 275/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0075 - mae: 0.0723\n",
      "Epoch 276/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0074 - mae: 0.0720\n",
      "Epoch 277/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0074 - mae: 0.0717\n",
      "Epoch 278/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0073 - mae: 0.0714\n",
      "Epoch 279/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0072 - mae: 0.0711\n",
      "Epoch 280/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0072 - mae: 0.0708\n",
      "Epoch 281/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0071 - mae: 0.0705\n",
      "Epoch 282/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0071 - mae: 0.0702\n",
      "Epoch 283/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0070 - mae: 0.0699\n",
      "Epoch 284/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0069 - mae: 0.0696\n",
      "Epoch 285/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0069 - mae: 0.0693\n",
      "Epoch 286/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0068 - mae: 0.0690\n",
      "Epoch 287/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0068 - mae: 0.0687\n",
      "Epoch 288/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0067 - mae: 0.0684\n",
      "Epoch 289/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0067 - mae: 0.0682\n",
      "Epoch 290/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0066 - mae: 0.0679\n",
      "Epoch 291/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0065 - mae: 0.0676\n",
      "Epoch 292/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0065 - mae: 0.0673\n",
      "Epoch 293/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0064 - mae: 0.0670\n",
      "Epoch 294/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0064 - mae: 0.0667\n",
      "Epoch 295/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0063 - mae: 0.0665\n",
      "Epoch 296/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0063 - mae: 0.0662\n",
      "Epoch 297/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0062 - mae: 0.0659\n",
      "Epoch 298/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0062 - mae: 0.0656\n",
      "Epoch 299/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0061 - mae: 0.0654\n",
      "Epoch 300/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0061 - mae: 0.0651\n",
      "Epoch 301/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0060 - mae: 0.0648\n",
      "Epoch 302/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0060 - mae: 0.0645\n",
      "Epoch 303/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0059 - mae: 0.0643\n",
      "Epoch 304/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0059 - mae: 0.0640\n",
      "Epoch 305/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0058 - mae: 0.0637\n",
      "Epoch 306/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0058 - mae: 0.0635\n",
      "Epoch 307/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0057 - mae: 0.0632\n",
      "Epoch 308/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0057 - mae: 0.0629\n",
      "Epoch 309/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0056 - mae: 0.0627\n",
      "Epoch 310/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0056 - mae: 0.0624\n",
      "Epoch 311/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0055 - mae: 0.0621\n",
      "Epoch 312/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0055 - mae: 0.0619\n",
      "Epoch 313/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0054 - mae: 0.0616\n",
      "Epoch 314/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0054 - mae: 0.0614\n",
      "Epoch 315/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0053 - mae: 0.0611\n",
      "Epoch 316/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0053 - mae: 0.0608\n",
      "Epoch 317/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0053 - mae: 0.0606\n",
      "Epoch 318/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0052 - mae: 0.0603\n",
      "Epoch 319/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0052 - mae: 0.0601\n",
      "Epoch 320/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0051 - mae: 0.0598\n",
      "Epoch 321/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0051 - mae: 0.0596\n",
      "Epoch 322/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0050 - mae: 0.0593\n",
      "Epoch 323/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0050 - mae: 0.0591\n",
      "Epoch 324/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0050 - mae: 0.0588\n",
      "Epoch 325/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0049 - mae: 0.0586\n",
      "Epoch 326/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0049 - mae: 0.0583\n",
      "Epoch 327/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0048 - mae: 0.0581\n",
      "Epoch 328/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0048 - mae: 0.0578\n",
      "Epoch 329/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0048 - mae: 0.0576\n",
      "Epoch 330/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0047 - mae: 0.0574\n",
      "Epoch 331/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0047 - mae: 0.0571\n",
      "Epoch 332/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0046 - mae: 0.0569\n",
      "Epoch 333/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0046 - mae: 0.0566\n",
      "Epoch 334/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0046 - mae: 0.0564\n",
      "Epoch 335/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0045 - mae: 0.0562\n",
      "Epoch 336/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0045 - mae: 0.0559\n",
      "Epoch 337/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0044 - mae: 0.0557\n",
      "Epoch 338/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0044 - mae: 0.0555\n",
      "Epoch 339/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0044 - mae: 0.0552\n",
      "Epoch 340/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0043 - mae: 0.0550\n",
      "Epoch 341/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0043 - mae: 0.0548\n",
      "Epoch 342/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0043 - mae: 0.0545\n",
      "Epoch 343/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0042 - mae: 0.0543\n",
      "Epoch 344/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0042 - mae: 0.0541\n",
      "Epoch 345/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0042 - mae: 0.0539\n",
      "Epoch 346/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0041 - mae: 0.0536\n",
      "Epoch 347/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0041 - mae: 0.0534\n",
      "Epoch 348/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0041 - mae: 0.0532\n",
      "Epoch 349/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0040 - mae: 0.0530\n",
      "Epoch 350/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0040 - mae: 0.0527\n",
      "Epoch 351/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0040 - mae: 0.0525\n",
      "Epoch 352/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0039 - mae: 0.0523\n",
      "Epoch 353/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0039 - mae: 0.0521\n",
      "Epoch 354/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0039 - mae: 0.0518\n",
      "Epoch 355/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0038 - mae: 0.0516\n",
      "Epoch 356/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0038 - mae: 0.0514\n",
      "Epoch 357/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mae: 0.0512\n",
      "Epoch 358/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0037 - mae: 0.0510\n",
      "Epoch 359/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0037 - mae: 0.0508\n",
      "Epoch 360/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0037 - mae: 0.0506\n",
      "Epoch 361/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0036 - mae: 0.0503\n",
      "Epoch 362/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0036 - mae: 0.0501\n",
      "Epoch 363/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0036 - mae: 0.0499\n",
      "Epoch 364/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0035 - mae: 0.0497\n",
      "Epoch 365/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0035 - mae: 0.0495\n",
      "Epoch 366/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0035 - mae: 0.0493\n",
      "Epoch 367/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0035 - mae: 0.0491\n",
      "Epoch 368/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0034 - mae: 0.0489\n",
      "Epoch 369/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0034 - mae: 0.0487\n",
      "Epoch 370/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0034 - mae: 0.0485\n",
      "Epoch 371/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0033 - mae: 0.0483\n",
      "Epoch 372/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0033 - mae: 0.0481\n",
      "Epoch 373/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0033 - mae: 0.0479\n",
      "Epoch 374/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0033 - mae: 0.0477\n",
      "Epoch 375/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0032 - mae: 0.0475\n",
      "Epoch 376/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0032 - mae: 0.0473\n",
      "Epoch 377/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0032 - mae: 0.0471\n",
      "Epoch 378/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0469\n",
      "Epoch 379/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0467\n",
      "Epoch 380/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0031 - mae: 0.0465\n",
      "Epoch 381/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0463\n",
      "Epoch 382/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0030 - mae: 0.0461\n",
      "Epoch 383/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0030 - mae: 0.0459\n",
      "Epoch 384/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0030 - mae: 0.0457\n",
      "Epoch 385/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0030 - mae: 0.0455\n",
      "Epoch 386/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0029 - mae: 0.0453\n",
      "Epoch 387/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0029 - mae: 0.0451\n",
      "Epoch 388/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0029 - mae: 0.0449\n",
      "Epoch 389/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0029 - mae: 0.0447\n",
      "Epoch 390/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0028 - mae: 0.0446\n",
      "Epoch 391/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0028 - mae: 0.0444\n",
      "Epoch 392/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0028 - mae: 0.0442\n",
      "Epoch 393/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0028 - mae: 0.0440\n",
      "Epoch 394/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0028 - mae: 0.0438\n",
      "Epoch 395/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0027 - mae: 0.0436\n",
      "Epoch 396/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0027 - mae: 0.0434\n",
      "Epoch 397/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0027 - mae: 0.0433\n",
      "Epoch 398/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0027 - mae: 0.0431\n",
      "Epoch 399/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0026 - mae: 0.0429\n",
      "Epoch 400/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0026 - mae: 0.0427\n",
      "Epoch 401/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0026 - mae: 0.0425\n",
      "Epoch 402/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0026 - mae: 0.0424\n",
      "Epoch 403/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0026 - mae: 0.0422\n",
      "Epoch 404/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0025 - mae: 0.0420\n",
      "Epoch 405/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0025 - mae: 0.0418\n",
      "Epoch 406/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0025 - mae: 0.0417\n",
      "Epoch 407/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0025 - mae: 0.0415\n",
      "Epoch 408/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0024 - mae: 0.0413\n",
      "Epoch 409/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0024 - mae: 0.0411\n",
      "Epoch 410/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0024 - mae: 0.0410\n",
      "Epoch 411/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0024 - mae: 0.0408\n",
      "Epoch 412/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0024 - mae: 0.0406\n",
      "Epoch 413/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0023 - mae: 0.0404\n",
      "Epoch 414/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0023 - mae: 0.0403\n",
      "Epoch 415/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0023 - mae: 0.0401\n",
      "Epoch 416/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0023 - mae: 0.0399\n",
      "Epoch 417/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0023 - mae: 0.0398\n",
      "Epoch 418/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0022 - mae: 0.0396\n",
      "Epoch 419/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0022 - mae: 0.0394\n",
      "Epoch 420/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0022 - mae: 0.0393\n",
      "Epoch 421/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0022 - mae: 0.0391\n",
      "Epoch 422/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0022 - mae: 0.0389\n",
      "Epoch 423/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0022 - mae: 0.0388\n",
      "Epoch 424/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0021 - mae: 0.0386\n",
      "Epoch 425/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0021 - mae: 0.0385\n",
      "Epoch 426/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0021 - mae: 0.0383\n",
      "Epoch 427/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0021 - mae: 0.0381\n",
      "Epoch 428/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0021 - mae: 0.0380\n",
      "Epoch 429/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0020 - mae: 0.0378\n",
      "Epoch 430/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0020 - mae: 0.0377\n",
      "Epoch 431/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0020 - mae: 0.0375\n",
      "Epoch 432/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0020 - mae: 0.0373\n",
      "Epoch 433/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0020 - mae: 0.0372\n",
      "Epoch 434/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0020 - mae: 0.0370\n",
      "Epoch 435/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0019 - mae: 0.0369\n",
      "Epoch 436/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0019 - mae: 0.0367\n",
      "Epoch 437/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0019 - mae: 0.0366\n",
      "Epoch 438/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0019 - mae: 0.0364\n",
      "Epoch 439/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0019 - mae: 0.0363\n",
      "Epoch 440/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0019 - mae: 0.0361\n",
      "Epoch 441/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0019 - mae: 0.0360\n",
      "Epoch 442/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0018 - mae: 0.0358\n",
      "Epoch 443/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0018 - mae: 0.0357\n",
      "Epoch 444/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0018 - mae: 0.0355\n",
      "Epoch 445/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0018 - mae: 0.0354\n",
      "Epoch 446/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0018 - mae: 0.0352\n",
      "Epoch 447/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0018 - mae: 0.0351\n",
      "Epoch 448/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0017 - mae: 0.0349\n",
      "Epoch 449/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0017 - mae: 0.0348\n",
      "Epoch 450/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0017 - mae: 0.0346\n",
      "Epoch 451/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0017 - mae: 0.0345\n",
      "Epoch 452/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0017 - mae: 0.0343\n",
      "Epoch 453/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0017 - mae: 0.0342\n",
      "Epoch 454/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0017 - mae: 0.0340\n",
      "Epoch 455/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0016 - mae: 0.0339\n",
      "Epoch 456/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0016 - mae: 0.0338\n",
      "Epoch 457/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0016 - mae: 0.0336\n",
      "Epoch 458/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0016 - mae: 0.0335\n",
      "Epoch 459/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0016 - mae: 0.0333\n",
      "Epoch 460/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0016 - mae: 0.0332\n",
      "Epoch 461/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0016 - mae: 0.0331\n",
      "Epoch 462/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0016 - mae: 0.0329\n",
      "Epoch 463/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0015 - mae: 0.0328\n",
      "Epoch 464/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0015 - mae: 0.0326\n",
      "Epoch 465/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0015 - mae: 0.0325\n",
      "Epoch 466/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0015 - mae: 0.0324\n",
      "Epoch 467/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0015 - mae: 0.0322\n",
      "Epoch 468/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0015 - mae: 0.0321\n",
      "Epoch 469/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0015 - mae: 0.0320\n",
      "Epoch 470/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0015 - mae: 0.0318\n",
      "Epoch 471/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0317\n",
      "Epoch 472/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0316\n",
      "Epoch 473/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0014 - mae: 0.0314\n",
      "Epoch 474/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0014 - mae: 0.0313\n",
      "Epoch 475/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0014 - mae: 0.0312\n",
      "Epoch 476/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0310\n",
      "Epoch 477/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0014 - mae: 0.0309\n",
      "Epoch 478/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0014 - mae: 0.0308\n",
      "Epoch 479/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0013 - mae: 0.0306\n",
      "Epoch 480/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0013 - mae: 0.0305\n",
      "Epoch 481/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0013 - mae: 0.0304\n",
      "Epoch 482/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0013 - mae: 0.0303\n",
      "Epoch 483/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0013 - mae: 0.0301\n",
      "Epoch 484/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0013 - mae: 0.0300\n",
      "Epoch 485/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0013 - mae: 0.0299\n",
      "Epoch 486/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0013 - mae: 0.0297\n",
      "Epoch 487/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0296\n",
      "Epoch 488/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0295\n",
      "Epoch 489/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0012 - mae: 0.0294\n",
      "Epoch 490/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0012 - mae: 0.0293\n",
      "Epoch 491/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0012 - mae: 0.0291\n",
      "Epoch 492/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0290\n",
      "Epoch 493/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0012 - mae: 0.0289\n",
      "Epoch 494/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0012 - mae: 0.0288\n",
      "Epoch 495/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0012 - mae: 0.0286\n",
      "Epoch 496/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0012 - mae: 0.0285\n",
      "Epoch 497/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0012 - mae: 0.0284\n",
      "Epoch 498/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0283\n",
      "Epoch 499/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0011 - mae: 0.0282\n",
      "Epoch 500/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0280\n",
      "Epoch 501/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0279\n",
      "Epoch 502/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0278\n",
      "Epoch 503/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0277\n",
      "Epoch 504/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0276\n",
      "Epoch 505/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0011 - mae: 0.0275\n",
      "Epoch 506/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0011 - mae: 0.0273\n",
      "Epoch 507/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0272\n",
      "Epoch 508/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0271\n",
      "Epoch 509/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0010 - mae: 0.0270\n",
      "Epoch 510/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0010 - mae: 0.0269\n",
      "Epoch 511/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0268\n",
      "Epoch 512/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0267\n",
      "Epoch 513/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0010 - mae: 0.0266\n",
      "Epoch 514/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0010 - mae: 0.0264\n",
      "Epoch 515/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 9.9354e-04 - mae: 0.0263\n",
      "Epoch 516/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.8521e-04 - mae: 0.0262\n",
      "Epoch 517/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9.7696e-04 - mae: 0.0261\n",
      "Epoch 518/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9.6877e-04 - mae: 0.0260\n",
      "Epoch 519/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9.6064e-04 - mae: 0.0259\n",
      "Epoch 520/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9.5259e-04 - mae: 0.0258\n",
      "Epoch 521/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.4462e-04 - mae: 0.0257\n",
      "Epoch 522/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9.3669e-04 - mae: 0.0256\n",
      "Epoch 523/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.2885e-04 - mae: 0.0255\n",
      "Epoch 524/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9.2105e-04 - mae: 0.0254\n",
      "Epoch 525/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.1334e-04 - mae: 0.0252\n",
      "Epoch 526/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.0569e-04 - mae: 0.0251\n",
      "Epoch 527/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.9809e-04 - mae: 0.0250\n",
      "Epoch 528/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 8.9057e-04 - mae: 0.0249\n",
      "Epoch 529/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 8.8311e-04 - mae: 0.0248\n",
      "Epoch 530/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 8.7570e-04 - mae: 0.0247\n",
      "Epoch 531/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 8.6837e-04 - mae: 0.0246\n",
      "Epoch 532/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.6108e-04 - mae: 0.0245\n",
      "Epoch 533/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 8.5385e-04 - mae: 0.0244\n",
      "Epoch 534/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 8.4669e-04 - mae: 0.0243\n",
      "Epoch 535/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.3962e-04 - mae: 0.0242\n",
      "Epoch 536/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.3259e-04 - mae: 0.0241\n",
      "Epoch 537/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.2559e-04 - mae: 0.0240\n",
      "Epoch 538/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.1868e-04 - mae: 0.0239\n",
      "Epoch 539/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.1183e-04 - mae: 0.0238\n",
      "Epoch 540/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.0501e-04 - mae: 0.0237\n",
      "Epoch 541/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7.9826e-04 - mae: 0.0236\n",
      "Epoch 542/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 7.9156e-04 - mae: 0.0235\n",
      "Epoch 543/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 7.8493e-04 - mae: 0.0234\n",
      "Epoch 544/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.7836e-04 - mae: 0.0233\n",
      "Epoch 545/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 7.7183e-04 - mae: 0.0232\n",
      "Epoch 546/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 7.6535e-04 - mae: 0.0231\n",
      "Epoch 547/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7.5895e-04 - mae: 0.0230\n",
      "Epoch 548/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7.5259e-04 - mae: 0.0229\n",
      "Epoch 549/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 7.4627e-04 - mae: 0.0228\n",
      "Epoch 550/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.4002e-04 - mae: 0.0227\n",
      "Epoch 551/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.3383e-04 - mae: 0.0226\n",
      "Epoch 552/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.2768e-04 - mae: 0.0225\n",
      "Epoch 553/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.2157e-04 - mae: 0.0224\n",
      "Epoch 554/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 7.1554e-04 - mae: 0.0223\n",
      "Epoch 555/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 7.0952e-04 - mae: 0.0223\n",
      "Epoch 556/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.0359e-04 - mae: 0.0222\n",
      "Epoch 557/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.9770e-04 - mae: 0.0221\n",
      "Epoch 558/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.9183e-04 - mae: 0.0220\n",
      "Epoch 559/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6.8603e-04 - mae: 0.0219\n",
      "Epoch 560/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.8029e-04 - mae: 0.0218\n",
      "Epoch 561/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.7458e-04 - mae: 0.0217\n",
      "Epoch 562/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.6894e-04 - mae: 0.0216\n",
      "Epoch 563/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.6334e-04 - mae: 0.0215\n",
      "Epoch 564/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.5776e-04 - mae: 0.0214\n",
      "Epoch 565/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.5225e-04 - mae: 0.0213\n",
      "Epoch 566/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6.4679e-04 - mae: 0.0212\n",
      "Epoch 567/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.4138e-04 - mae: 0.0212\n",
      "Epoch 568/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.3598e-04 - mae: 0.0211\n",
      "Epoch 569/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.3065e-04 - mae: 0.0210\n",
      "Epoch 570/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.2536e-04 - mae: 0.0209\n",
      "Epoch 571/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.2012e-04 - mae: 0.0208\n",
      "Epoch 572/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.1494e-04 - mae: 0.0207\n",
      "Epoch 573/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.0978e-04 - mae: 0.0206\n",
      "Epoch 574/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.0467e-04 - mae: 0.0205\n",
      "Epoch 575/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.9961e-04 - mae: 0.0205\n",
      "Epoch 576/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.9459e-04 - mae: 0.0204\n",
      "Epoch 577/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.8958e-04 - mae: 0.0203\n",
      "Epoch 578/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.8465e-04 - mae: 0.0202\n",
      "Epoch 579/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.7975e-04 - mae: 0.0201\n",
      "Epoch 580/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.7490e-04 - mae: 0.0200\n",
      "Epoch 581/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.7008e-04 - mae: 0.0199\n",
      "Epoch 582/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.6530e-04 - mae: 0.0199\n",
      "Epoch 583/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.6056e-04 - mae: 0.0198\n",
      "Epoch 584/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.5586e-04 - mae: 0.0197\n",
      "Epoch 585/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.5119e-04 - mae: 0.0196\n",
      "Epoch 586/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.4658e-04 - mae: 0.0195\n",
      "Epoch 587/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.4199e-04 - mae: 0.0194\n",
      "Epoch 588/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.3746e-04 - mae: 0.0194\n",
      "Epoch 589/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.3295e-04 - mae: 0.0193\n",
      "Epoch 590/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.2850e-04 - mae: 0.0192\n",
      "Epoch 591/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.2405e-04 - mae: 0.0191\n",
      "Epoch 592/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.1966e-04 - mae: 0.0190\n",
      "Epoch 593/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.1531e-04 - mae: 0.0190\n",
      "Epoch 594/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.1098e-04 - mae: 0.0189\n",
      "Epoch 595/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.0671e-04 - mae: 0.0188\n",
      "Epoch 596/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.0246e-04 - mae: 0.0187\n",
      "Epoch 597/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.9823e-04 - mae: 0.0186\n",
      "Epoch 598/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.9408e-04 - mae: 0.0186\n",
      "Epoch 599/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.8993e-04 - mae: 0.0185\n",
      "Epoch 600/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.8583e-04 - mae: 0.0184\n",
      "Epoch 601/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.8174e-04 - mae: 0.0183\n",
      "Epoch 602/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.7771e-04 - mae: 0.0183\n",
      "Epoch 603/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.7371e-04 - mae: 0.0182\n",
      "Epoch 604/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.6974e-04 - mae: 0.0181\n",
      "Epoch 605/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.6579e-04 - mae: 0.0180\n",
      "Epoch 606/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.6189e-04 - mae: 0.0180\n",
      "Epoch 607/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.5802e-04 - mae: 0.0179\n",
      "Epoch 608/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.5419e-04 - mae: 0.0178\n",
      "Epoch 609/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.5037e-04 - mae: 0.0177\n",
      "Epoch 610/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.4660e-04 - mae: 0.0177\n",
      "Epoch 611/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.4286e-04 - mae: 0.0176\n",
      "Epoch 612/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.3915e-04 - mae: 0.0175\n",
      "Epoch 613/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.3548e-04 - mae: 0.0174\n",
      "Epoch 614/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.3182e-04 - mae: 0.0174\n",
      "Epoch 615/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.2820e-04 - mae: 0.0173\n",
      "Epoch 616/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.2461e-04 - mae: 0.0172\n",
      "Epoch 617/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.2105e-04 - mae: 0.0171\n",
      "Epoch 618/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.1753e-04 - mae: 0.0171\n",
      "Epoch 619/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.1402e-04 - mae: 0.0170\n",
      "Epoch 620/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.1056e-04 - mae: 0.0169\n",
      "Epoch 621/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.0711e-04 - mae: 0.0169\n",
      "Epoch 622/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.0369e-04 - mae: 0.0168\n",
      "Epoch 623/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.0032e-04 - mae: 0.0167\n",
      "Epoch 624/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.9696e-04 - mae: 0.0166\n",
      "Epoch 625/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.9363e-04 - mae: 0.0166\n",
      "Epoch 626/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.9033e-04 - mae: 0.0165\n",
      "Epoch 627/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.8706e-04 - mae: 0.0164\n",
      "Epoch 628/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.8381e-04 - mae: 0.0164\n",
      "Epoch 629/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.8060e-04 - mae: 0.0163\n",
      "Epoch 630/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.7741e-04 - mae: 0.0162\n",
      "Epoch 631/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 3.7425e-04 - mae: 0.0162\n",
      "Epoch 632/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.7112e-04 - mae: 0.0161\n",
      "Epoch 633/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.6799e-04 - mae: 0.0160\n",
      "Epoch 634/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.6492e-04 - mae: 0.0160\n",
      "Epoch 635/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.6185e-04 - mae: 0.0159\n",
      "Epoch 636/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.5882e-04 - mae: 0.0158\n",
      "Epoch 637/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.5582e-04 - mae: 0.0158\n",
      "Epoch 638/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.5284e-04 - mae: 0.0157\n",
      "Epoch 639/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.4988e-04 - mae: 0.0156\n",
      "Epoch 640/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.4694e-04 - mae: 0.0156\n",
      "Epoch 641/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.4405e-04 - mae: 0.0155\n",
      "Epoch 642/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.4116e-04 - mae: 0.0154\n",
      "Epoch 643/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.3830e-04 - mae: 0.0154\n",
      "Epoch 644/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.3546e-04 - mae: 0.0153\n",
      "Epoch 645/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.3264e-04 - mae: 0.0152\n",
      "Epoch 646/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.2986e-04 - mae: 0.0152\n",
      "Epoch 647/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.2708e-04 - mae: 0.0151\n",
      "Epoch 648/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.2435e-04 - mae: 0.0150\n",
      "Epoch 649/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.2164e-04 - mae: 0.0150\n",
      "Epoch 650/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.1893e-04 - mae: 0.0149\n",
      "Epoch 651/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.1626e-04 - mae: 0.0149\n",
      "Epoch 652/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.1361e-04 - mae: 0.0148\n",
      "Epoch 653/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.1099e-04 - mae: 0.0147\n",
      "Epoch 654/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.0838e-04 - mae: 0.0147\n",
      "Epoch 655/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.0580e-04 - mae: 0.0146\n",
      "Epoch 656/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.0324e-04 - mae: 0.0145\n",
      "Epoch 657/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.0069e-04 - mae: 0.0145\n",
      "Epoch 658/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.9817e-04 - mae: 0.0144\n",
      "Epoch 659/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.9567e-04 - mae: 0.0144\n",
      "Epoch 660/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.9319e-04 - mae: 0.0143\n",
      "Epoch 661/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.9073e-04 - mae: 0.0142\n",
      "Epoch 662/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.8829e-04 - mae: 0.0142\n",
      "Epoch 663/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.8588e-04 - mae: 0.0141\n",
      "Epoch 664/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.8349e-04 - mae: 0.0141\n",
      "Epoch 665/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.8112e-04 - mae: 0.0140\n",
      "Epoch 666/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.7875e-04 - mae: 0.0139\n",
      "Epoch 667/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.7642e-04 - mae: 0.0139\n",
      "Epoch 668/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.7410e-04 - mae: 0.0138\n",
      "Epoch 669/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.7181e-04 - mae: 0.0138\n",
      "Epoch 670/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.6953e-04 - mae: 0.0137\n",
      "Epoch 671/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.6727e-04 - mae: 0.0137\n",
      "Epoch 672/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.6503e-04 - mae: 0.0136\n",
      "Epoch 673/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.6280e-04 - mae: 0.0135\n",
      "Epoch 674/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.6060e-04 - mae: 0.0135\n",
      "Epoch 675/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.5842e-04 - mae: 0.0134\n",
      "Epoch 676/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.5626e-04 - mae: 0.0134\n",
      "Epoch 677/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.5411e-04 - mae: 0.0133\n",
      "Epoch 678/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.5197e-04 - mae: 0.0133\n",
      "Epoch 679/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.4987e-04 - mae: 0.0132\n",
      "Epoch 680/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.4777e-04 - mae: 0.0131\n",
      "Epoch 681/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.4570e-04 - mae: 0.0131\n",
      "Epoch 682/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.4364e-04 - mae: 0.0130\n",
      "Epoch 683/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.4159e-04 - mae: 0.0130\n",
      "Epoch 684/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.3957e-04 - mae: 0.0129\n",
      "Epoch 685/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.3755e-04 - mae: 0.0129\n",
      "Epoch 686/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.3557e-04 - mae: 0.0128\n",
      "Epoch 687/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.3360e-04 - mae: 0.0128\n",
      "Epoch 688/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.3163e-04 - mae: 0.0127\n",
      "Epoch 689/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.2970e-04 - mae: 0.0127\n",
      "Epoch 690/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.2777e-04 - mae: 0.0126\n",
      "Epoch 691/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.2587e-04 - mae: 0.0126\n",
      "Epoch 692/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.2397e-04 - mae: 0.0125\n",
      "Epoch 693/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.2209e-04 - mae: 0.0124\n",
      "Epoch 694/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.2022e-04 - mae: 0.0124\n",
      "Epoch 695/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.1838e-04 - mae: 0.0123\n",
      "Epoch 696/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.1656e-04 - mae: 0.0123\n",
      "Epoch 697/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.1474e-04 - mae: 0.0122\n",
      "Epoch 698/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.1294e-04 - mae: 0.0122\n",
      "Epoch 699/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.1115e-04 - mae: 0.0121\n",
      "Epoch 700/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.0938e-04 - mae: 0.0121\n",
      "Epoch 701/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.0763e-04 - mae: 0.0120\n",
      "Epoch 702/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.0589e-04 - mae: 0.0120\n",
      "Epoch 703/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.0416e-04 - mae: 0.0119\n",
      "Epoch 704/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.0245e-04 - mae: 0.0119\n",
      "Epoch 705/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.0075e-04 - mae: 0.0118\n",
      "Epoch 706/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.9907e-04 - mae: 0.0118\n",
      "Epoch 707/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.9740e-04 - mae: 0.0117\n",
      "Epoch 708/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.9575e-04 - mae: 0.0117\n",
      "Epoch 709/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.9410e-04 - mae: 0.0116\n",
      "Epoch 710/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.9249e-04 - mae: 0.0116\n",
      "Epoch 711/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.9087e-04 - mae: 0.0115\n",
      "Epoch 712/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.8926e-04 - mae: 0.0115\n",
      "Epoch 713/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.8768e-04 - mae: 0.0114\n",
      "Epoch 714/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 1.8610e-04 - mae: 0.0114\n",
      "Epoch 715/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.8455e-04 - mae: 0.0113\n",
      "Epoch 716/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.8300e-04 - mae: 0.0113\n",
      "Epoch 717/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.8147e-04 - mae: 0.0113\n",
      "Epoch 718/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.7995e-04 - mae: 0.0112\n",
      "Epoch 719/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7844e-04 - mae: 0.0112\n",
      "Epoch 720/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7695e-04 - mae: 0.0111\n",
      "Epoch 721/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.7546e-04 - mae: 0.0111\n",
      "Epoch 722/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.7399e-04 - mae: 0.0110\n",
      "Epoch 723/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7253e-04 - mae: 0.0110\n",
      "Epoch 724/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.7109e-04 - mae: 0.0109\n",
      "Epoch 725/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6965e-04 - mae: 0.0109\n",
      "Epoch 726/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6823e-04 - mae: 0.0108\n",
      "Epoch 727/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6681e-04 - mae: 0.0108\n",
      "Epoch 728/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6542e-04 - mae: 0.0107\n",
      "Epoch 729/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6404e-04 - mae: 0.0107\n",
      "Epoch 730/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6266e-04 - mae: 0.0107\n",
      "Epoch 731/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6130e-04 - mae: 0.0106\n",
      "Epoch 732/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5995e-04 - mae: 0.0106\n",
      "Epoch 733/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5861e-04 - mae: 0.0105\n",
      "Epoch 734/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5727e-04 - mae: 0.0105\n",
      "Epoch 735/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5596e-04 - mae: 0.0104\n",
      "Epoch 736/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5465e-04 - mae: 0.0104\n",
      "Epoch 737/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.5335e-04 - mae: 0.0103\n",
      "Epoch 738/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.5206e-04 - mae: 0.0103\n",
      "Epoch 739/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5079e-04 - mae: 0.0103\n",
      "Epoch 740/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4952e-04 - mae: 0.0102\n",
      "Epoch 741/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4827e-04 - mae: 0.0102\n",
      "Epoch 742/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4703e-04 - mae: 0.0101\n",
      "Epoch 743/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4580e-04 - mae: 0.0101\n",
      "Epoch 744/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4457e-04 - mae: 0.0100\n",
      "Epoch 745/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4337e-04 - mae: 0.0100\n",
      "Epoch 746/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4217e-04 - mae: 0.0100\n",
      "Epoch 747/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4097e-04 - mae: 0.0099\n",
      "Epoch 748/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3980e-04 - mae: 0.0099\n",
      "Epoch 749/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3862e-04 - mae: 0.0098\n",
      "Epoch 750/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3745e-04 - mae: 0.0098\n",
      "Epoch 751/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3631e-04 - mae: 0.0098\n",
      "Epoch 752/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3516e-04 - mae: 0.0097\n",
      "Epoch 753/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3404e-04 - mae: 0.0097\n",
      "Epoch 754/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3291e-04 - mae: 0.0096\n",
      "Epoch 755/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3179e-04 - mae: 0.0096\n",
      "Epoch 756/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3069e-04 - mae: 0.0096\n",
      "Epoch 757/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2959e-04 - mae: 0.0095\n",
      "Epoch 758/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2851e-04 - mae: 0.0095\n",
      "Epoch 759/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2743e-04 - mae: 0.0094\n",
      "Epoch 760/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2636e-04 - mae: 0.0094\n",
      "Epoch 761/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.2531e-04 - mae: 0.0094\n",
      "Epoch 762/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.2425e-04 - mae: 0.0093\n",
      "Epoch 763/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2321e-04 - mae: 0.0093\n",
      "Epoch 764/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2218e-04 - mae: 0.0092\n",
      "Epoch 765/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2115e-04 - mae: 0.0092\n",
      "Epoch 766/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2014e-04 - mae: 0.0092\n",
      "Epoch 767/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1913e-04 - mae: 0.0091\n",
      "Epoch 768/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1814e-04 - mae: 0.0091\n",
      "Epoch 769/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1714e-04 - mae: 0.0090\n",
      "Epoch 770/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1616e-04 - mae: 0.0090\n",
      "Epoch 771/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1519e-04 - mae: 0.0090\n",
      "Epoch 772/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1422e-04 - mae: 0.0089\n",
      "Epoch 773/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1327e-04 - mae: 0.0089\n",
      "Epoch 774/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1232e-04 - mae: 0.0089\n",
      "Epoch 775/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1138e-04 - mae: 0.0088\n",
      "Epoch 776/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1044e-04 - mae: 0.0088\n",
      "Epoch 777/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0952e-04 - mae: 0.0087\n",
      "Epoch 778/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0859e-04 - mae: 0.0087\n",
      "Epoch 779/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0768e-04 - mae: 0.0087\n",
      "Epoch 780/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0678e-04 - mae: 0.0086\n",
      "Epoch 781/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0589e-04 - mae: 0.0086\n",
      "Epoch 782/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0500e-04 - mae: 0.0086\n",
      "Epoch 783/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 1.0413e-04 - mae: 0.0085\n",
      "Epoch 784/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.0325e-04 - mae: 0.0085\n",
      "Epoch 785/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 1.0238e-04 - mae: 0.0085\n",
      "Epoch 786/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0153e-04 - mae: 0.0084\n",
      "Epoch 787/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0068e-04 - mae: 0.0084\n",
      "Epoch 788/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.9830e-05 - mae: 0.0083\n",
      "Epoch 789/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.8995e-05 - mae: 0.0083\n",
      "Epoch 790/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.8168e-05 - mae: 0.0083\n",
      "Epoch 791/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9.7342e-05 - mae: 0.0082\n",
      "Epoch 792/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.6524e-05 - mae: 0.0082\n",
      "Epoch 793/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 9.5717e-05 - mae: 0.0082\n",
      "Epoch 794/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 9.4913e-05 - mae: 0.0081\n",
      "Epoch 795/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9.4118e-05 - mae: 0.0081\n",
      "Epoch 796/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9.3331e-05 - mae: 0.0081\n",
      "Epoch 797/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9.2550e-05 - mae: 0.0080\n",
      "Epoch 798/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9.1777e-05 - mae: 0.0080\n",
      "Epoch 799/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.1005e-05 - mae: 0.0080\n",
      "Epoch 800/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9.0244e-05 - mae: 0.0079\n",
      "Epoch 801/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 8.9490e-05 - mae: 0.0079\n",
      "Epoch 802/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.8738e-05 - mae: 0.0079\n",
      "Epoch 803/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 8.7987e-05 - mae: 0.0078\n",
      "Epoch 804/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.7252e-05 - mae: 0.0078\n",
      "Epoch 805/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.6524e-05 - mae: 0.0078\n",
      "Epoch 806/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.5802e-05 - mae: 0.0077\n",
      "Epoch 807/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 8.5078e-05 - mae: 0.0077\n",
      "Epoch 808/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 8.4366e-05 - mae: 0.0077\n",
      "Epoch 809/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 8.3656e-05 - mae: 0.0076\n",
      "Epoch 810/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.2956e-05 - mae: 0.0076\n",
      "Epoch 811/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 8.2261e-05 - mae: 0.0076\n",
      "Epoch 812/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.1567e-05 - mae: 0.0075\n",
      "Epoch 813/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.0883e-05 - mae: 0.0075\n",
      "Epoch 814/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.0210e-05 - mae: 0.0075\n",
      "Epoch 815/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7.9542e-05 - mae: 0.0075\n",
      "Epoch 816/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.8873e-05 - mae: 0.0074\n",
      "Epoch 817/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.8207e-05 - mae: 0.0074\n",
      "Epoch 818/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.7550e-05 - mae: 0.0074\n",
      "Epoch 819/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 7.6901e-05 - mae: 0.0073\n",
      "Epoch 820/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.6259e-05 - mae: 0.0073\n",
      "Epoch 821/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.5623e-05 - mae: 0.0073\n",
      "Epoch 822/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 7.4986e-05 - mae: 0.0072\n",
      "Epoch 823/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 7.4361e-05 - mae: 0.0072\n",
      "Epoch 824/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 7.3737e-05 - mae: 0.0072\n",
      "Epoch 825/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7.3116e-05 - mae: 0.0071\n",
      "Epoch 826/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 7.2506e-05 - mae: 0.0071\n",
      "Epoch 827/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7.1897e-05 - mae: 0.0071\n",
      "Epoch 828/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7.1290e-05 - mae: 0.0071\n",
      "Epoch 829/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 7.0701e-05 - mae: 0.0070\n",
      "Epoch 830/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7.0108e-05 - mae: 0.0070\n",
      "Epoch 831/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 6.9512e-05 - mae: 0.0070\n",
      "Epoch 832/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.8934e-05 - mae: 0.0069\n",
      "Epoch 833/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.8359e-05 - mae: 0.0069\n",
      "Epoch 834/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.7782e-05 - mae: 0.0069\n",
      "Epoch 835/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.7214e-05 - mae: 0.0068\n",
      "Epoch 836/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6.6650e-05 - mae: 0.0068\n",
      "Epoch 837/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.6093e-05 - mae: 0.0068\n",
      "Epoch 838/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.5536e-05 - mae: 0.0068\n",
      "Epoch 839/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.4991e-05 - mae: 0.0067\n",
      "Epoch 840/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.4444e-05 - mae: 0.0067\n",
      "Epoch 841/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.3904e-05 - mae: 0.0067\n",
      "Epoch 842/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.3372e-05 - mae: 0.0067\n",
      "Epoch 843/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.2835e-05 - mae: 0.0066\n",
      "Epoch 844/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.2311e-05 - mae: 0.0066\n",
      "Epoch 845/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.1794e-05 - mae: 0.0066\n",
      "Epoch 846/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.1272e-05 - mae: 0.0065\n",
      "Epoch 847/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.0758e-05 - mae: 0.0065\n",
      "Epoch 848/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.0248e-05 - mae: 0.0065\n",
      "Epoch 849/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.9744e-05 - mae: 0.0065\n",
      "Epoch 850/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.9241e-05 - mae: 0.0064\n",
      "Epoch 851/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.8751e-05 - mae: 0.0064\n",
      "Epoch 852/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.8254e-05 - mae: 0.0064\n",
      "Epoch 853/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.7764e-05 - mae: 0.0063\n",
      "Epoch 854/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.7279e-05 - mae: 0.0063\n",
      "Epoch 855/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.6803e-05 - mae: 0.0063\n",
      "Epoch 856/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.6325e-05 - mae: 0.0063\n",
      "Epoch 857/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 5.5855e-05 - mae: 0.0062\n",
      "Epoch 858/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 5.5388e-05 - mae: 0.0062\n",
      "Epoch 859/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.4921e-05 - mae: 0.0062\n",
      "Epoch 860/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.4459e-05 - mae: 0.0062\n",
      "Epoch 861/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.4003e-05 - mae: 0.0061\n",
      "Epoch 862/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.3550e-05 - mae: 0.0061\n",
      "Epoch 863/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.3105e-05 - mae: 0.0061\n",
      "Epoch 864/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.2659e-05 - mae: 0.0061\n",
      "Epoch 865/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.2217e-05 - mae: 0.0060\n",
      "Epoch 866/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.1782e-05 - mae: 0.0060\n",
      "Epoch 867/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.1345e-05 - mae: 0.0060\n",
      "Epoch 868/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.0915e-05 - mae: 0.0060\n",
      "Epoch 869/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.0490e-05 - mae: 0.0059\n",
      "Epoch 870/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.0068e-05 - mae: 0.0059\n",
      "Epoch 871/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.9642e-05 - mae: 0.0059\n",
      "Epoch 872/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.9230e-05 - mae: 0.0059\n",
      "Epoch 873/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.8816e-05 - mae: 0.0058\n",
      "Epoch 874/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.8406e-05 - mae: 0.0058\n",
      "Epoch 875/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.7998e-05 - mae: 0.0058\n",
      "Epoch 876/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.7597e-05 - mae: 0.0058\n",
      "Epoch 877/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.7200e-05 - mae: 0.0057\n",
      "Epoch 878/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.6804e-05 - mae: 0.0057\n",
      "Epoch 879/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.6408e-05 - mae: 0.0057\n",
      "Epoch 880/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.6024e-05 - mae: 0.0057\n",
      "Epoch 881/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.5639e-05 - mae: 0.0056\n",
      "Epoch 882/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.5256e-05 - mae: 0.0056\n",
      "Epoch 883/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.4877e-05 - mae: 0.0056\n",
      "Epoch 884/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.4499e-05 - mae: 0.0056\n",
      "Epoch 885/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.4127e-05 - mae: 0.0055\n",
      "Epoch 886/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.3753e-05 - mae: 0.0055\n",
      "Epoch 887/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.3390e-05 - mae: 0.0055\n",
      "Epoch 888/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.3026e-05 - mae: 0.0055\n",
      "Epoch 889/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.2664e-05 - mae: 0.0055\n",
      "Epoch 890/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.2305e-05 - mae: 0.0054\n",
      "Epoch 891/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.1953e-05 - mae: 0.0054\n",
      "Epoch 892/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.1601e-05 - mae: 0.0054\n",
      "Epoch 893/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.1255e-05 - mae: 0.0054\n",
      "Epoch 894/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.0905e-05 - mae: 0.0053\n",
      "Epoch 895/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.0564e-05 - mae: 0.0053\n",
      "Epoch 896/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.0227e-05 - mae: 0.0053\n",
      "Epoch 897/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.9888e-05 - mae: 0.0053\n",
      "Epoch 898/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.9551e-05 - mae: 0.0053\n",
      "Epoch 899/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.9224e-05 - mae: 0.0052\n",
      "Epoch 900/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.8894e-05 - mae: 0.0052\n",
      "Epoch 901/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.8569e-05 - mae: 0.0052\n",
      "Epoch 902/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.8244e-05 - mae: 0.0052\n",
      "Epoch 903/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.7928e-05 - mae: 0.0051\n",
      "Epoch 904/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.7607e-05 - mae: 0.0051\n",
      "Epoch 905/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.7292e-05 - mae: 0.0051\n",
      "Epoch 906/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.6978e-05 - mae: 0.0051\n",
      "Epoch 907/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.6668e-05 - mae: 0.0051\n",
      "Epoch 908/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.6362e-05 - mae: 0.0050\n",
      "Epoch 909/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.6056e-05 - mae: 0.0050\n",
      "Epoch 910/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.5756e-05 - mae: 0.0050\n",
      "Epoch 911/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.5453e-05 - mae: 0.0050\n",
      "Epoch 912/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.5159e-05 - mae: 0.0050\n",
      "Epoch 913/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.4862e-05 - mae: 0.0049\n",
      "Epoch 914/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.4571e-05 - mae: 0.0049\n",
      "Epoch 915/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.4281e-05 - mae: 0.0049\n",
      "Epoch 916/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.3994e-05 - mae: 0.0049\n",
      "Epoch 917/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.3711e-05 - mae: 0.0049\n",
      "Epoch 918/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.3425e-05 - mae: 0.0048\n",
      "Epoch 919/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.3148e-05 - mae: 0.0048\n",
      "Epoch 920/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.2869e-05 - mae: 0.0048\n",
      "Epoch 921/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.2593e-05 - mae: 0.0048\n",
      "Epoch 922/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.2320e-05 - mae: 0.0047\n",
      "Epoch 923/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.2052e-05 - mae: 0.0047\n",
      "Epoch 924/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.1778e-05 - mae: 0.0047\n",
      "Epoch 925/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 3.1513e-05 - mae: 0.0047\n",
      "Epoch 926/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.1250e-05 - mae: 0.0047\n",
      "Epoch 927/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.0990e-05 - mae: 0.0047\n",
      "Epoch 928/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.0730e-05 - mae: 0.0046\n",
      "Epoch 929/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.0468e-05 - mae: 0.0046\n",
      "Epoch 930/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.0217e-05 - mae: 0.0046\n",
      "Epoch 931/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.9963e-05 - mae: 0.0046\n",
      "Epoch 932/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.9713e-05 - mae: 0.0046\n",
      "Epoch 933/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.9464e-05 - mae: 0.0045\n",
      "Epoch 934/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.9214e-05 - mae: 0.0045\n",
      "Epoch 935/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.8970e-05 - mae: 0.0045\n",
      "Epoch 936/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.8729e-05 - mae: 0.0045\n",
      "Epoch 937/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.8485e-05 - mae: 0.0045\n",
      "Epoch 938/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.8250e-05 - mae: 0.0044\n",
      "Epoch 939/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.8011e-05 - mae: 0.0044\n",
      "Epoch 940/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.7778e-05 - mae: 0.0044\n",
      "Epoch 941/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.7545e-05 - mae: 0.0044\n",
      "Epoch 942/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.7313e-05 - mae: 0.0044\n",
      "Epoch 943/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.7084e-05 - mae: 0.0043\n",
      "Epoch 944/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.6858e-05 - mae: 0.0043\n",
      "Epoch 945/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.6631e-05 - mae: 0.0043\n",
      "Epoch 946/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.6409e-05 - mae: 0.0043\n",
      "Epoch 947/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.6185e-05 - mae: 0.0043\n",
      "Epoch 948/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.5968e-05 - mae: 0.0043\n",
      "Epoch 949/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.5751e-05 - mae: 0.0042\n",
      "Epoch 950/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.5535e-05 - mae: 0.0042\n",
      "Epoch 951/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.5321e-05 - mae: 0.0042\n",
      "Epoch 952/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.5108e-05 - mae: 0.0042\n",
      "Epoch 953/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.4899e-05 - mae: 0.0042\n",
      "Epoch 954/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.4690e-05 - mae: 0.0042\n",
      "Epoch 955/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.4482e-05 - mae: 0.0041\n",
      "Epoch 956/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.4278e-05 - mae: 0.0041\n",
      "Epoch 957/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.4073e-05 - mae: 0.0041\n",
      "Epoch 958/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.3875e-05 - mae: 0.0041\n",
      "Epoch 959/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.3673e-05 - mae: 0.0041\n",
      "Epoch 960/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.3473e-05 - mae: 0.0040\n",
      "Epoch 961/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.3278e-05 - mae: 0.0040\n",
      "Epoch 962/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.3082e-05 - mae: 0.0040\n",
      "Epoch 963/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.2889e-05 - mae: 0.0040\n",
      "Epoch 964/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.2695e-05 - mae: 0.0040\n",
      "Epoch 965/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.2508e-05 - mae: 0.0040\n",
      "Epoch 966/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.2319e-05 - mae: 0.0039\n",
      "Epoch 967/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.2130e-05 - mae: 0.0039\n",
      "Epoch 968/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.1947e-05 - mae: 0.0039\n",
      "Epoch 969/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.1763e-05 - mae: 0.0039\n",
      "Epoch 970/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.1579e-05 - mae: 0.0039\n",
      "Epoch 971/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.1398e-05 - mae: 0.0039\n",
      "Epoch 972/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.1220e-05 - mae: 0.0038\n",
      "Epoch 973/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.1041e-05 - mae: 0.0038\n",
      "Epoch 974/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.0864e-05 - mae: 0.0038\n",
      "Epoch 975/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.0692e-05 - mae: 0.0038\n",
      "Epoch 976/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.0517e-05 - mae: 0.0038\n",
      "Epoch 977/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.0347e-05 - mae: 0.0038\n",
      "Epoch 978/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.0174e-05 - mae: 0.0038\n",
      "Epoch 979/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.0005e-05 - mae: 0.0037\n",
      "Epoch 980/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.9837e-05 - mae: 0.0037\n",
      "Epoch 981/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.9672e-05 - mae: 0.0037\n",
      "Epoch 982/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.9506e-05 - mae: 0.0037\n",
      "Epoch 983/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.9344e-05 - mae: 0.0037\n",
      "Epoch 984/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.9180e-05 - mae: 0.0037\n",
      "Epoch 985/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.9021e-05 - mae: 0.0036\n",
      "Epoch 986/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.8862e-05 - mae: 0.0036\n",
      "Epoch 987/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.8703e-05 - mae: 0.0036\n",
      "Epoch 988/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.8547e-05 - mae: 0.0036\n",
      "Epoch 989/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 1.8390e-05 - mae: 0.0036\n",
      "Epoch 990/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.8239e-05 - mae: 0.0036\n",
      "Epoch 991/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.8084e-05 - mae: 0.0036\n",
      "Epoch 992/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.7933e-05 - mae: 0.0035\n",
      "Epoch 993/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.7781e-05 - mae: 0.0035\n",
      "Epoch 994/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.7630e-05 - mae: 0.0035\n",
      "Epoch 995/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.7483e-05 - mae: 0.0035\n",
      "Epoch 996/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.7338e-05 - mae: 0.0035\n",
      "Epoch 997/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.7193e-05 - mae: 0.0035\n",
      "Epoch 998/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.7050e-05 - mae: 0.0034\n",
      "Epoch 999/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.6905e-05 - mae: 0.0034\n",
      "Epoch 1000/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.6764e-05 - mae: 0.0034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7c64ce18e090>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습하기\n",
    "model.fit(x_train, y_train, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Variable path=sequential/dense/kernel, shape=(1, 1), dtype=float32, value=[[2.001265]]>, <Variable path=sequential/dense/bias, shape=(1,), dtype=float32, value=[0.99119264]>]\n"
     ]
    }
   ],
   "source": [
    "# 모델 가중치 확인하기\n",
    "print(model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight : [[2.001265]]\n",
      "bias : [0.99119264]\n"
     ]
    }
   ],
   "source": [
    "# 모델 레이어의 가중치 출력하기\n",
    "print(f'weight : {model.layers[0].weights[0].numpy()}')\n",
    "print(f'bias : {model.layers[0].bias.numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "[[23.005108]\n",
      " [25.006372]\n",
      " [27.007637]]\n"
     ]
    }
   ],
   "source": [
    "# 학습 완료된 모델 사용하여 예측하기\n",
    "print(model.predict(np.array([[11],[12],[13]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method fit in module keras.src.backend.tensorflow.trainer:\n",
      "\n",
      "fit(x=None, y=None, batch_size=None, epochs=1, verbose='auto', callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_batch_size=None, validation_freq=1) method of keras.src.models.sequential.Sequential instance\n",
      "    Trains the model for a fixed number of epochs (dataset iterations).\n",
      "\n",
      "    Args:\n",
      "        x: Input data. It can be:\n",
      "            - A NumPy array (or array-like), or a list of arrays\n",
      "            (in case the model has multiple inputs).\n",
      "            - A backend-native tensor, or a list of tensors\n",
      "            (in case the model has multiple inputs).\n",
      "            - A dict mapping input names to the corresponding array/tensors,\n",
      "            if the model has named inputs.\n",
      "            - A `keras.utils.PyDataset` returning `(inputs, targets)` or\n",
      "            `(inputs, targets, sample_weights)`.\n",
      "            - A `tf.data.Dataset` yielding `(inputs, targets)` or\n",
      "            `(inputs, targets, sample_weights)`.\n",
      "            - A `torch.utils.data.DataLoader` yielding `(inputs, targets)`\n",
      "            or `(inputs, targets, sample_weights)`.\n",
      "            - A Python generator function yielding `(inputs, targets)` or\n",
      "            `(inputs, targets, sample_weights)`.\n",
      "        y: Target data. Like the input data `x`, it can be either NumPy\n",
      "            array(s) or backend-native tensor(s). If `x` is a\n",
      "            `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      "            `torch.utils.data.DataLoader` or a Python generator function,\n",
      "            `y` should not be specified since targets will be obtained from\n",
      "            `x`.\n",
      "        batch_size: Integer or `None`.\n",
      "            Number of samples per gradient update.\n",
      "            If unspecified, `batch_size` will default to 32.\n",
      "            Do not specify the `batch_size` if your input data `x` is a\n",
      "            `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      "            `torch.utils.data.DataLoader` or Python generator function\n",
      "            since they generate batches.\n",
      "        epochs: Integer. Number of epochs to train the model.\n",
      "            An epoch is an iteration over the entire `x` and `y`\n",
      "            data provided\n",
      "            (unless the `steps_per_epoch` flag is set to\n",
      "            something other than None).\n",
      "            Note that in conjunction with `initial_epoch`,\n",
      "            `epochs` is to be understood as \"final epoch\".\n",
      "            The model is not trained for a number of iterations\n",
      "            given by `epochs`, but merely until the epoch\n",
      "            of index `epochs` is reached.\n",
      "        verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n",
      "            0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      "            \"auto\" becomes 1 for most cases.\n",
      "            Note that the progress bar is not\n",
      "            particularly useful when logged to a file,\n",
      "            so `verbose=2` is recommended when not running interactively\n",
      "            (e.g., in a production environment). Defaults to `\"auto\"`.\n",
      "        callbacks: List of `keras.callbacks.Callback` instances.\n",
      "            List of callbacks to apply during training.\n",
      "            See `keras.callbacks`. Note\n",
      "            `keras.callbacks.ProgbarLogger` and\n",
      "            `keras.callbacks.History` callbacks are created\n",
      "            automatically and need not be passed to `model.fit()`.\n",
      "            `keras.callbacks.ProgbarLogger` is created\n",
      "            or not based on the `verbose` argument in `model.fit()`.\n",
      "        validation_split: Float between 0 and 1.\n",
      "            Fraction of the training data to be used as validation data.\n",
      "            The model will set apart this fraction of the training data,\n",
      "            will not train on it, and will evaluate the loss and any model\n",
      "            metrics on this data at the end of each epoch. The validation\n",
      "            data is selected from the last samples in the `x` and `y` data\n",
      "            provided, before shuffling.\n",
      "            This argument is only supported when `x` and `y` are made of\n",
      "            NumPy arrays or tensors.\n",
      "            If both `validation_data` and `validation_split` are provided,\n",
      "            `validation_data` will override `validation_split`.\n",
      "        validation_data: Data on which to evaluate\n",
      "            the loss and any model metrics at the end of each epoch.\n",
      "            The model will not be trained on this data. Thus, note the fact\n",
      "            that the validation loss of data provided using\n",
      "            `validation_split` or `validation_data` is not affected by\n",
      "            regularization layers like noise and dropout.\n",
      "            `validation_data` will override `validation_split`.\n",
      "            It can be:\n",
      "            - A tuple `(x_val, y_val)` of NumPy arrays or tensors.\n",
      "            - A tuple `(x_val, y_val, val_sample_weights)` of NumPy\n",
      "            arrays.\n",
      "            - A `keras.utils.PyDataset`, a `tf.data.Dataset`, a\n",
      "            `torch.utils.data.DataLoader` yielding `(inputs, targets)` or a\n",
      "            Python generator function yielding `(x_val, y_val)` or\n",
      "            `(inputs, targets, sample_weights)`.\n",
      "        shuffle: Boolean, whether to shuffle the training data before each\n",
      "            epoch. This argument is ignored when `x` is a\n",
      "            `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      "            `torch.utils.data.DataLoader` or Python generator function.\n",
      "        class_weight: Optional dictionary mapping class indices (integers)\n",
      "            to a weight (float) value, used for weighting the loss function\n",
      "            (during training only).\n",
      "            This can be useful to tell the model to\n",
      "            \"pay more attention\" to samples from\n",
      "            an under-represented class. When `class_weight` is specified\n",
      "            and targets have a rank of 2 or greater, either `y` must be\n",
      "            one-hot encoded, or an explicit final dimension of `1` must\n",
      "            be included for sparse class labels.\n",
      "        sample_weight: Optional NumPy array or tensor of weights for\n",
      "            the training samples, used for weighting the loss function\n",
      "            (during training only). You can either pass a flat (1D)\n",
      "            NumPy array or tensor with the same length as the input samples\n",
      "            (1:1 mapping between weights and samples), or in the case of\n",
      "            temporal data, you can pass a 2D NumPy array or tensor with\n",
      "            shape `(samples, sequence_length)` to apply a different weight\n",
      "            to every timestep of every sample.\n",
      "            This argument is not supported when `x` is a\n",
      "            `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      "            `torch.utils.data.DataLoader` or Python generator function.\n",
      "            Instead, provide `sample_weights` as the third element of `x`.\n",
      "            Note that sample weighting does not apply to metrics specified\n",
      "            via the `metrics` argument in `compile()`. To apply sample\n",
      "            weighting to your metrics, you can specify them via the\n",
      "            `weighted_metrics` in `compile()` instead.\n",
      "        initial_epoch: Integer.\n",
      "            Epoch at which to start training\n",
      "            (useful for resuming a previous training run).\n",
      "        steps_per_epoch: Integer or `None`.\n",
      "            Total number of steps (batches of samples) before declaring one\n",
      "            epoch finished and starting the next epoch. When training with\n",
      "            input tensors or NumPy arrays, the default `None` means that the\n",
      "            value used is the number of samples in your dataset divided by\n",
      "            the batch size, or 1 if that cannot be determined.\n",
      "            If `x` is a `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      "            `torch.utils.data.DataLoader` or Python generator function, the\n",
      "            epoch will run until the input dataset is exhausted. When\n",
      "            passing an infinitely repeating dataset, you must specify the\n",
      "            `steps_per_epoch` argument, otherwise the training will run\n",
      "            indefinitely.\n",
      "        validation_steps: Integer or `None`.\n",
      "            Only relevant if `validation_data` is provided.\n",
      "            Total number of steps (batches of samples) to draw before\n",
      "            stopping when performing validation at the end of every epoch.\n",
      "            If `validation_steps` is `None`, validation will run until the\n",
      "            `validation_data` dataset is exhausted. In the case of an\n",
      "            infinitely repeating dataset, it will run indefinitely. If\n",
      "            `validation_steps` is specified and only part of the dataset\n",
      "            is consumed, the evaluation will start from the beginning of the\n",
      "            dataset at each epoch. This ensures that the same validation\n",
      "            samples are used every time.\n",
      "        validation_batch_size: Integer or `None`.\n",
      "            Number of samples per validation batch.\n",
      "            If unspecified, will default to `batch_size`.\n",
      "            Do not specify the `validation_batch_size` if your data is a\n",
      "            `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      "            `torch.utils.data.DataLoader` or Python generator function\n",
      "            since they generate batches.\n",
      "        validation_freq: Only relevant if validation data is provided.\n",
      "            Specifies how many training epochs to run\n",
      "            before a new validation run is performed,\n",
      "            e.g. `validation_freq=2` runs validation every 2 epochs.\n",
      "\n",
      "    Unpacking behavior for iterator-like inputs:\n",
      "        A common pattern is to pass an iterator like object such as a\n",
      "        `tf.data.Dataset` or a `keras.utils.PyDataset` to `fit()`,\n",
      "        which will in fact yield not only features (`x`)\n",
      "        but optionally targets (`y`) and sample weights (`sample_weight`).\n",
      "        Keras requires that the output of such iterator-likes be\n",
      "        unambiguous. The iterator should return a tuple\n",
      "        of length 1, 2, or 3, where the optional second and third elements\n",
      "        will be used for `y` and `sample_weight` respectively.\n",
      "        Any other type provided will be wrapped in\n",
      "        a length-one tuple, effectively treating everything as `x`. When\n",
      "        yielding dicts, they should still adhere to the top-level tuple\n",
      "        structure,\n",
      "        e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
      "        features, targets, and weights from the keys of a single dict.\n",
      "        A notable unsupported data type is the `namedtuple`. The reason is\n",
      "        that it behaves like both an ordered datatype (tuple) and a mapping\n",
      "        datatype (dict). So given a namedtuple of the form:\n",
      "        `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
      "        it is ambiguous whether to reverse the order of the elements when\n",
      "        interpreting the value. Even worse is a tuple of the form:\n",
      "        `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
      "        where it is unclear if the tuple was intended to be unpacked\n",
      "        into `x`, `y`, and `sample_weight` or passed through\n",
      "        as a single element to `x`.\n",
      "\n",
      "    Returns:\n",
      "        A `History` object. Its `History.history` attribute is\n",
      "        a record of training loss values and metrics values\n",
      "        at successive epochs, as well as validation loss values\n",
      "        and validation metrics values (if applicable).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 클래스와 메소드 사용법 확인하기\n",
    "help(model.fit)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 심층신경망으로 항공사 고객 만족 분류 모델 구현 실습하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 데이터 로드 및 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# 경고 메시지를 무시하도록 설정하기\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 129880 entries, 0 to 129879\n",
      "Data columns (total 23 columns):\n",
      " #   Column                             Non-Null Count   Dtype  \n",
      "---  ------                             --------------   -----  \n",
      " 0   satisfaction                       129880 non-null  object \n",
      " 1   Gender                             129880 non-null  object \n",
      " 2   Customer Type                      129880 non-null  object \n",
      " 3   Age                                129880 non-null  int64  \n",
      " 4   Type of Travel                     129880 non-null  object \n",
      " 5   Class                              129880 non-null  object \n",
      " 6   Flight Distance                    129880 non-null  int64  \n",
      " 7   Seat comfort                       129880 non-null  int64  \n",
      " 8   Departure/Arrival time convenient  129880 non-null  int64  \n",
      " 9   Food and drink                     129880 non-null  int64  \n",
      " 10  Gate location                      129880 non-null  int64  \n",
      " 11  Inflight wifi service              129880 non-null  int64  \n",
      " 12  Inflight entertainment             129880 non-null  int64  \n",
      " 13  Online support                     129880 non-null  int64  \n",
      " 14  Ease of Online booking             129880 non-null  int64  \n",
      " 15  On-board service                   129880 non-null  int64  \n",
      " 16  Leg room service                   129880 non-null  int64  \n",
      " 17  Baggage handling                   129880 non-null  int64  \n",
      " 18  Checkin service                    129880 non-null  int64  \n",
      " 19  Cleanliness                        129880 non-null  int64  \n",
      " 20  Online boarding                    129880 non-null  int64  \n",
      " 21  Departure Delay in Minutes         129880 non-null  int64  \n",
      " 22  Arrival Delay in Minutes           129487 non-null  float64\n",
      "dtypes: float64(1), int64(17), object(5)\n",
      "memory usage: 22.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# csv 파일에서 데이터를 로드해서 데이터프레임으로 저장하기\n",
    "df = pd.read_csv('Invistico_Airline.csv')\n",
    "\n",
    "# 데이터프레임 정보 확인하기\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Customer Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Type of Travel</th>\n",
       "      <th>Class</th>\n",
       "      <th>Flight Distance</th>\n",
       "      <th>Seat comfort</th>\n",
       "      <th>Departure/Arrival time convenient</th>\n",
       "      <th>Food and drink</th>\n",
       "      <th>...</th>\n",
       "      <th>Online support</th>\n",
       "      <th>Ease of Online booking</th>\n",
       "      <th>On-board service</th>\n",
       "      <th>Leg room service</th>\n",
       "      <th>Baggage handling</th>\n",
       "      <th>Checkin service</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Online boarding</th>\n",
       "      <th>Departure Delay in Minutes</th>\n",
       "      <th>Arrival Delay in Minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>satisfied</td>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>65</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>satisfied</td>\n",
       "      <td>Male</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>47</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>2464</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>310</td>\n",
       "      <td>305.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>satisfied</td>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>15</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "      <td>2138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>satisfied</td>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>60</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "      <td>623</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>satisfied</td>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>70</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  satisfaction  Gender   Customer Type  Age   Type of Travel     Class  \\\n",
       "0    satisfied  Female  Loyal Customer   65  Personal Travel       Eco   \n",
       "1    satisfied    Male  Loyal Customer   47  Personal Travel  Business   \n",
       "2    satisfied  Female  Loyal Customer   15  Personal Travel       Eco   \n",
       "3    satisfied  Female  Loyal Customer   60  Personal Travel       Eco   \n",
       "4    satisfied  Female  Loyal Customer   70  Personal Travel       Eco   \n",
       "\n",
       "   Flight Distance  Seat comfort  Departure/Arrival time convenient  \\\n",
       "0              265             0                                  0   \n",
       "1             2464             0                                  0   \n",
       "2             2138             0                                  0   \n",
       "3              623             0                                  0   \n",
       "4              354             0                                  0   \n",
       "\n",
       "   Food and drink  ...  Online support  Ease of Online booking  \\\n",
       "0               0  ...               2                       3   \n",
       "1               0  ...               2                       3   \n",
       "2               0  ...               2                       2   \n",
       "3               0  ...               3                       1   \n",
       "4               0  ...               4                       2   \n",
       "\n",
       "   On-board service  Leg room service  Baggage handling  Checkin service  \\\n",
       "0                 3                 0                 3                5   \n",
       "1                 4                 4                 4                2   \n",
       "2                 3                 3                 4                4   \n",
       "3                 1                 0                 1                4   \n",
       "4                 2                 0                 2                4   \n",
       "\n",
       "   Cleanliness  Online boarding  Departure Delay in Minutes  \\\n",
       "0            3                2                           0   \n",
       "1            3                2                         310   \n",
       "2            4                2                           0   \n",
       "3            1                3                           0   \n",
       "4            2                5                           0   \n",
       "\n",
       "   Arrival Delay in Minutes  \n",
       "0                       0.0  \n",
       "1                     305.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터프레임의 처음 5개 행의 데이터 출력하기\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Flight Distance</th>\n",
       "      <th>Seat comfort</th>\n",
       "      <th>Departure/Arrival time convenient</th>\n",
       "      <th>Food and drink</th>\n",
       "      <th>Gate location</th>\n",
       "      <th>Inflight wifi service</th>\n",
       "      <th>Inflight entertainment</th>\n",
       "      <th>Online support</th>\n",
       "      <th>Ease of Online booking</th>\n",
       "      <th>On-board service</th>\n",
       "      <th>Leg room service</th>\n",
       "      <th>Baggage handling</th>\n",
       "      <th>Checkin service</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Online boarding</th>\n",
       "      <th>Departure Delay in Minutes</th>\n",
       "      <th>Arrival Delay in Minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129487.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.427957</td>\n",
       "      <td>1981.409055</td>\n",
       "      <td>2.838597</td>\n",
       "      <td>2.990645</td>\n",
       "      <td>2.851994</td>\n",
       "      <td>2.990422</td>\n",
       "      <td>3.249130</td>\n",
       "      <td>3.383477</td>\n",
       "      <td>3.519703</td>\n",
       "      <td>3.472105</td>\n",
       "      <td>3.465075</td>\n",
       "      <td>3.485902</td>\n",
       "      <td>3.695673</td>\n",
       "      <td>3.340807</td>\n",
       "      <td>3.705759</td>\n",
       "      <td>3.352587</td>\n",
       "      <td>14.713713</td>\n",
       "      <td>15.091129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.119360</td>\n",
       "      <td>1027.115606</td>\n",
       "      <td>1.392983</td>\n",
       "      <td>1.527224</td>\n",
       "      <td>1.443729</td>\n",
       "      <td>1.305970</td>\n",
       "      <td>1.318818</td>\n",
       "      <td>1.346059</td>\n",
       "      <td>1.306511</td>\n",
       "      <td>1.305560</td>\n",
       "      <td>1.270836</td>\n",
       "      <td>1.292226</td>\n",
       "      <td>1.156483</td>\n",
       "      <td>1.260582</td>\n",
       "      <td>1.151774</td>\n",
       "      <td>1.298715</td>\n",
       "      <td>38.071126</td>\n",
       "      <td>38.465650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>1359.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>1925.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>2544.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>85.000000</td>\n",
       "      <td>6951.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1592.000000</td>\n",
       "      <td>1584.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Age  Flight Distance   Seat comfort  \\\n",
       "count  129880.000000    129880.000000  129880.000000   \n",
       "mean       39.427957      1981.409055       2.838597   \n",
       "std        15.119360      1027.115606       1.392983   \n",
       "min         7.000000        50.000000       0.000000   \n",
       "25%        27.000000      1359.000000       2.000000   \n",
       "50%        40.000000      1925.000000       3.000000   \n",
       "75%        51.000000      2544.000000       4.000000   \n",
       "max        85.000000      6951.000000       5.000000   \n",
       "\n",
       "       Departure/Arrival time convenient  Food and drink  Gate location  \\\n",
       "count                      129880.000000   129880.000000  129880.000000   \n",
       "mean                            2.990645        2.851994       2.990422   \n",
       "std                             1.527224        1.443729       1.305970   \n",
       "min                             0.000000        0.000000       0.000000   \n",
       "25%                             2.000000        2.000000       2.000000   \n",
       "50%                             3.000000        3.000000       3.000000   \n",
       "75%                             4.000000        4.000000       4.000000   \n",
       "max                             5.000000        5.000000       5.000000   \n",
       "\n",
       "       Inflight wifi service  Inflight entertainment  Online support  \\\n",
       "count          129880.000000           129880.000000   129880.000000   \n",
       "mean                3.249130                3.383477        3.519703   \n",
       "std                 1.318818                1.346059        1.306511   \n",
       "min                 0.000000                0.000000        0.000000   \n",
       "25%                 2.000000                2.000000        3.000000   \n",
       "50%                 3.000000                4.000000        4.000000   \n",
       "75%                 4.000000                4.000000        5.000000   \n",
       "max                 5.000000                5.000000        5.000000   \n",
       "\n",
       "       Ease of Online booking  On-board service  Leg room service  \\\n",
       "count           129880.000000     129880.000000     129880.000000   \n",
       "mean                 3.472105          3.465075          3.485902   \n",
       "std                  1.305560          1.270836          1.292226   \n",
       "min                  0.000000          0.000000          0.000000   \n",
       "25%                  2.000000          3.000000          2.000000   \n",
       "50%                  4.000000          4.000000          4.000000   \n",
       "75%                  5.000000          4.000000          5.000000   \n",
       "max                  5.000000          5.000000          5.000000   \n",
       "\n",
       "       Baggage handling  Checkin service    Cleanliness  Online boarding  \\\n",
       "count     129880.000000    129880.000000  129880.000000    129880.000000   \n",
       "mean           3.695673         3.340807       3.705759         3.352587   \n",
       "std            1.156483         1.260582       1.151774         1.298715   \n",
       "min            1.000000         0.000000       0.000000         0.000000   \n",
       "25%            3.000000         3.000000       3.000000         2.000000   \n",
       "50%            4.000000         3.000000       4.000000         4.000000   \n",
       "75%            5.000000         4.000000       5.000000         4.000000   \n",
       "max            5.000000         5.000000       5.000000         5.000000   \n",
       "\n",
       "       Departure Delay in Minutes  Arrival Delay in Minutes  \n",
       "count               129880.000000             129487.000000  \n",
       "mean                    14.713713                 15.091129  \n",
       "std                     38.071126                 38.465650  \n",
       "min                      0.000000                  0.000000  \n",
       "25%                      0.000000                  0.000000  \n",
       "50%                      0.000000                  0.000000  \n",
       "75%                     12.000000                 13.000000  \n",
       "max                   1592.000000               1584.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터프레임의 요약 통계량 확인하기\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "satisfaction                           0\n",
       "Gender                                 0\n",
       "Customer Type                          0\n",
       "Age                                    0\n",
       "Type of Travel                         0\n",
       "Class                                  0\n",
       "Flight Distance                        0\n",
       "Seat comfort                           0\n",
       "Departure/Arrival time convenient      0\n",
       "Food and drink                         0\n",
       "Gate location                          0\n",
       "Inflight wifi service                  0\n",
       "Inflight entertainment                 0\n",
       "Online support                         0\n",
       "Ease of Online booking                 0\n",
       "On-board service                       0\n",
       "Leg room service                       0\n",
       "Baggage handling                       0\n",
       "Checkin service                        0\n",
       "Cleanliness                            0\n",
       "Online boarding                        0\n",
       "Departure Delay in Minutes             0\n",
       "Arrival Delay in Minutes             393\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 확인하기\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 데이터 전처리하기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 결측치 처리하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimpleImputer 객체로 결측치 대체하기\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "df[\"Arrival Delay in Minutes\"] = mean_imputer.fit_transform(df[[\"Arrival Delay in Minutes\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) 데이터 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object 칼럼 유형을 string 유형으로 변경하기\n",
    "cols = ['satisfaction', 'Gender', 'Customer Type', 'Type of Travel', 'Class']\n",
    "df[cols] = df[cols].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 데이터를 수치값으로 변경하기\n",
    "df['satisfaction'].replace(['dissatisfied','satisfied'], [0,1], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 순서형 인코딩(Ordinal Encoding)하기\n",
    "categories = pd.Categorical(\n",
    "    df['Class'], \n",
    "    categories= ['Eco', 'Eco Plus', 'Business'], \n",
    "    ordered=True)\n",
    "labels, unique = pd.factorize(categories, sort=True)\n",
    "df['Class'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원핫 인코딩(One Hot Encoding)하기\n",
    "cat_cols = ['Gender','Customer Type','Type of Travel']\n",
    "df = pd.get_dummies(df, columns=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "      <th>Flight Distance</th>\n",
       "      <th>Seat comfort</th>\n",
       "      <th>Departure/Arrival time convenient</th>\n",
       "      <th>Food and drink</th>\n",
       "      <th>Gate location</th>\n",
       "      <th>Inflight wifi service</th>\n",
       "      <th>Inflight entertainment</th>\n",
       "      <th>...</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Online boarding</th>\n",
       "      <th>Departure Delay in Minutes</th>\n",
       "      <th>Arrival Delay in Minutes</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Customer Type_Loyal Customer</th>\n",
       "      <th>Customer Type_disloyal Customer</th>\n",
       "      <th>Type of Travel_Business travel</th>\n",
       "      <th>Type of Travel_Personal Travel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>2464</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>310</td>\n",
       "      <td>305.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>623</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction  Age  Class  Flight Distance  Seat comfort  \\\n",
       "0             1   65      0              265             0   \n",
       "1             1   47      2             2464             0   \n",
       "2             1   15      0             2138             0   \n",
       "3             1   60      0              623             0   \n",
       "4             1   70      0              354             0   \n",
       "\n",
       "   Departure/Arrival time convenient  Food and drink  Gate location  \\\n",
       "0                                  0               0              2   \n",
       "1                                  0               0              3   \n",
       "2                                  0               0              3   \n",
       "3                                  0               0              3   \n",
       "4                                  0               0              3   \n",
       "\n",
       "   Inflight wifi service  Inflight entertainment  ...  Cleanliness  \\\n",
       "0                      2                       4  ...            3   \n",
       "1                      0                       2  ...            3   \n",
       "2                      2                       0  ...            4   \n",
       "3                      3                       4  ...            1   \n",
       "4                      4                       3  ...            2   \n",
       "\n",
       "   Online boarding  Departure Delay in Minutes  Arrival Delay in Minutes  \\\n",
       "0                2                           0                       0.0   \n",
       "1                2                         310                     305.0   \n",
       "2                2                           0                       0.0   \n",
       "3                3                           0                       0.0   \n",
       "4                5                           0                       0.0   \n",
       "\n",
       "   Gender_Female  Gender_Male  Customer Type_Loyal Customer  \\\n",
       "0           True        False                          True   \n",
       "1          False         True                          True   \n",
       "2           True        False                          True   \n",
       "3           True        False                          True   \n",
       "4           True        False                          True   \n",
       "\n",
       "   Customer Type_disloyal Customer  Type of Travel_Business travel  \\\n",
       "0                            False                           False   \n",
       "1                            False                           False   \n",
       "2                            False                           False   \n",
       "3                            False                           False   \n",
       "4                            False                           False   \n",
       "\n",
       "   Type of Travel_Personal Travel  \n",
       "0                            True  \n",
       "1                            True  \n",
       "2                            True  \n",
       "3                            True  \n",
       "4                            True  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 전처리 결과 확인하기\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "satisfaction                           int64\n",
       "Age                                    int64\n",
       "Class                                  int64\n",
       "Flight Distance                        int64\n",
       "Seat comfort                           int64\n",
       "Departure/Arrival time convenient      int64\n",
       "Food and drink                         int64\n",
       "Gate location                          int64\n",
       "Inflight wifi service                  int64\n",
       "Inflight entertainment                 int64\n",
       "Online support                         int64\n",
       "Ease of Online booking                 int64\n",
       "On-board service                       int64\n",
       "Leg room service                       int64\n",
       "Baggage handling                       int64\n",
       "Checkin service                        int64\n",
       "Cleanliness                            int64\n",
       "Online boarding                        int64\n",
       "Departure Delay in Minutes             int64\n",
       "Arrival Delay in Minutes             float64\n",
       "Gender_Female                           bool\n",
       "Gender_Male                             bool\n",
       "Customer Type_Loyal Customer            bool\n",
       "Customer Type_disloyal Customer         bool\n",
       "Type of Travel_Business travel          bool\n",
       "Type of Travel_Personal Travel          bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 유형 확인하기\n",
    "df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) 데이터셋 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터셋 크기 : X_train (103904, 25), y_train (103904,)\n",
      "검증 데이터셋 크기 : X_val (25976, 25), y_val (25976,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터셋을 입력(X)과 레이블(y)로 분리하기\n",
    "X = df.drop(['satisfaction'], axis=1)\n",
    "y = df['satisfaction'].reset_index(drop=True)\n",
    "\n",
    "# 데이터셋을 훈련 데이터와 검증 데이터로 분리하기\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y)\n",
    "\n",
    "print(f'훈련 데이터셋 크기 : X_train {X_train.shape}, y_train {y_train.shape}')\n",
    "print(f'검증 데이터셋 크기 : X_val {X_val.shape}, y_val {y_val.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) 데이터 스케일링하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.15384615 0.         0.34502246 ... 1.         1.         0.        ]\n",
      " [0.33333333 0.         0.44051587 ... 1.         1.         0.        ]\n",
      " [0.48717949 0.         0.26546877 ... 0.         1.         0.        ]\n",
      " ...\n",
      " [0.35897436 1.         0.31459209 ... 0.         1.         0.        ]\n",
      " [0.17948718 0.         0.25010868 ... 0.         0.         1.        ]\n",
      " [0.19230769 1.         0.62860455 ... 0.         1.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 데이터 정규화하기\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 심층신경망 모델 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 10:42:14.420874: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750902134.427890   25091 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750902134.430096   25091 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750902134.436014   25091 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750902134.436021   25091 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750902134.436023   25091 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750902134.436023   25091 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-26 10:42:14.438195: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "W0000 00:00:1750902135.514369   25091 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization \n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import random\n",
    "\n",
    "# 모델 시드 고정하기\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Keras의 Sequential 객체로 딥러닝 모델 구성하기\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=42) #모델 시드 고정하기\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_shape=(25,),kernel_initializer=initializer))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,633</span> (84.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,633\u001b[0m (84.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,633</span> (84.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,633\u001b[0m (84.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 구조 및 파라미터 정보 확인하기\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) 모델 컴파일하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 학습시킬 최적화 방법, loss 계산 방법, 평가 방법 설정하기\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8304 - loss: 0.3652 - val_accuracy: 0.9217 - val_loss: 0.1890\n",
      "Epoch 2/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9215 - loss: 0.1916 - val_accuracy: 0.9351 - val_loss: 0.1513\n",
      "Epoch 3/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 950us/step - accuracy: 0.9340 - loss: 0.1571 - val_accuracy: 0.9393 - val_loss: 0.1368\n",
      "Epoch 4/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 951us/step - accuracy: 0.9401 - loss: 0.1412 - val_accuracy: 0.9446 - val_loss: 0.1282\n",
      "Epoch 5/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 945us/step - accuracy: 0.9435 - loss: 0.1336 - val_accuracy: 0.9441 - val_loss: 0.1253\n",
      "Epoch 6/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 951us/step - accuracy: 0.9452 - loss: 0.1269 - val_accuracy: 0.9460 - val_loss: 0.1220\n",
      "Epoch 7/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 933us/step - accuracy: 0.9475 - loss: 0.1221 - val_accuracy: 0.9441 - val_loss: 0.1245\n",
      "Epoch 8/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 958us/step - accuracy: 0.9491 - loss: 0.1173 - val_accuracy: 0.9480 - val_loss: 0.1186\n",
      "Epoch 9/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 948us/step - accuracy: 0.9499 - loss: 0.1151 - val_accuracy: 0.9479 - val_loss: 0.1170\n",
      "Epoch 10/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 941us/step - accuracy: 0.9495 - loss: 0.1136 - val_accuracy: 0.9506 - val_loss: 0.1109\n",
      "Epoch 11/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 959us/step - accuracy: 0.9509 - loss: 0.1119 - val_accuracy: 0.9506 - val_loss: 0.1130\n",
      "Epoch 12/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 945us/step - accuracy: 0.9511 - loss: 0.1105 - val_accuracy: 0.9524 - val_loss: 0.1099\n",
      "Epoch 13/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9520 - loss: 0.1078 - val_accuracy: 0.9520 - val_loss: 0.1099\n",
      "Epoch 14/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 936us/step - accuracy: 0.9532 - loss: 0.1078 - val_accuracy: 0.9523 - val_loss: 0.1073\n",
      "Epoch 15/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 941us/step - accuracy: 0.9537 - loss: 0.1045 - val_accuracy: 0.9517 - val_loss: 0.1106\n",
      "Epoch 16/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9540 - loss: 0.1046 - val_accuracy: 0.9529 - val_loss: 0.1071\n",
      "Epoch 17/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 948us/step - accuracy: 0.9543 - loss: 0.1032 - val_accuracy: 0.9537 - val_loss: 0.1047\n",
      "Epoch 18/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 950us/step - accuracy: 0.9549 - loss: 0.1013 - val_accuracy: 0.9537 - val_loss: 0.1073\n",
      "Epoch 19/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 991us/step - accuracy: 0.9554 - loss: 0.1002 - val_accuracy: 0.9509 - val_loss: 0.1111\n",
      "Epoch 20/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 959us/step - accuracy: 0.9554 - loss: 0.1007 - val_accuracy: 0.9545 - val_loss: 0.1043\n",
      "Epoch 21/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 957us/step - accuracy: 0.9561 - loss: 0.0983 - val_accuracy: 0.9553 - val_loss: 0.1041\n",
      "Epoch 22/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 953us/step - accuracy: 0.9564 - loss: 0.0982 - val_accuracy: 0.9506 - val_loss: 0.1169\n",
      "Epoch 23/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 944us/step - accuracy: 0.9572 - loss: 0.0964 - val_accuracy: 0.9559 - val_loss: 0.1015\n",
      "Epoch 24/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 971us/step - accuracy: 0.9576 - loss: 0.0951 - val_accuracy: 0.9535 - val_loss: 0.1064\n",
      "Epoch 25/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 939us/step - accuracy: 0.9576 - loss: 0.0960 - val_accuracy: 0.9511 - val_loss: 0.1103\n",
      "Epoch 26/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 980us/step - accuracy: 0.9579 - loss: 0.0946 - val_accuracy: 0.9544 - val_loss: 0.1042\n",
      "Epoch 27/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 978us/step - accuracy: 0.9579 - loss: 0.0941 - val_accuracy: 0.9529 - val_loss: 0.1066\n",
      "Epoch 28/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 943us/step - accuracy: 0.9591 - loss: 0.0938 - val_accuracy: 0.9543 - val_loss: 0.1055\n",
      "Epoch 29/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 962us/step - accuracy: 0.9590 - loss: 0.0929 - val_accuracy: 0.9552 - val_loss: 0.1032\n",
      "Epoch 30/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 962us/step - accuracy: 0.9598 - loss: 0.0912 - val_accuracy: 0.9550 - val_loss: 0.1040\n",
      "Epoch 31/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 947us/step - accuracy: 0.9596 - loss: 0.0905 - val_accuracy: 0.9544 - val_loss: 0.1021\n",
      "Epoch 32/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 951us/step - accuracy: 0.9597 - loss: 0.0913 - val_accuracy: 0.9556 - val_loss: 0.1028\n",
      "Epoch 33/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 962us/step - accuracy: 0.9596 - loss: 0.0915 - val_accuracy: 0.9540 - val_loss: 0.1090\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습하기\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=128,\n",
    "          verbose=1, validation_data=(X_val, y_val), callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) 모델 훈련 과정 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 훈련 과정 정확도(accuracy) 시각화하기\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# 훈련 과정 손실(loss) 시각화하기\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
